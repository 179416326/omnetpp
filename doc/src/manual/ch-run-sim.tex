\chapter{Configuring and Running Simulations}
\label{cha:run-sim}

\section{Configuring simulations}

Configuration and input data for the simulation are in
a configuration file usually called \fname{omnetpp.ini}.
Some entries in this file apply to Tkenv or Cmdenv only, other
settings are in effect regardless of the user interface.
Both user interfaces accept command-line arguments, too.

The following sections explain \fname{omnetpp.ini}.

\section{The configuration file: omnetpp.ini}

\subsection{An example}

For a start, let us see a simple \fname{omnetpp.ini} file which
can be used to run the Fifo example simulation.

\begin{verbatim}
[General]
network = FifoNet
sim-time-limit = 100h
cpu-time-limit = 300s
#debug-on-errors = true
#record-eventlog = true

[Config Fifo1]
description = "low job arrival rate"
**.gen.sendIaTime = exponential(0.2s)
**.gen.msgLength = 100b
**.fifo.bitsPerSec = 1000bps

[Config Fifo2]
description = "high job arrival rate"
**.gen.sendIaTime = exponential(0.01s)
**.gen.msgLength = 10b
**.fifo.bitsPerSec = 1000bps
\end{verbatim}

The file is grouped into \textit{sections} named \ttt{[General]}, \ttt{[Config Fifo1]}
and \ttt{[Config Fifo2]}, each one containing several \textit{entries}.

Lines that start with ``\#'' are comments.

When you build the Fifo example with Cmdenv and you run it by typing \fname{fifo1}
(or on Unix, \fname{./fifo1}) on the command prompt, you should see
something like this.

\begin{verbatim}
OMNeT++ Discrete Event Simulation  (C) 1992-2003 Andras Varga
See the license for distribution terms and warranty disclaimer
Setting up Cmdenv (command-line user interface)...

Preparing for Run #1...
Setting up network `fifonet1'...
Running simulation...
** Event #0        T=0.0000000   Elapsed: 0m  0s
** Event #100000   T=25321.99    Elapsed: 0m  1s
** Event #200000   T=50275.694   Elapsed: 0m  3s
** Event #300000   T=75217.597   Elapsed: 0m  5s
** Event #400000   T=100125.76   Elapsed: 0m  6s
** Event #500000   T=125239.67   Elapsed: 0m  8s
...
** Event #1700000  T=424529.21   Elapsed: 0m 28s
** Event #1800000  T=449573.47   Elapsed: 0m 30s
** Event #1900000  T=474429.06   Elapsed: 0m 32s
** Event #2000000  T=499417.66   Elapsed: 0m 34s
<!> Simulation time limit reached -- simulation stopped.
\end{verbatim}

As Cmdenv runs the simulation, periodically it prints the sequence number
of the current event, the simulation time, the elapsed (real) time,
and the performance of the simulation (how many events are processed per
second; the first two values are 0 because there wasn't enough data
for it to calculate yet). At the end of the simulation, the \fname{finish()}
methods of the simple modules are run, and the output from them are displayed.
On my machine this run took 34 seconds. This Cmdenv output can be
customized via \fname{omnetpp.ini} entries. The output file \fname{fifo1.vec}
contains vector data recorded during simulation (here, queueing times),
and it can be processed using Plove or other tools.

\subsection{The concept of simulation runs}

{\opp} can execute several simulation runs automatically one after
another. If multiple runs\index{simulation!multiple runs} are
selected, option settings and parameter values can be given either
individually for each run, or together for all runs, depending in
which section the option or parameter appears.

\subsection{File syntax}

The ini file is a text file consisting of entries grouped into different sections.
The order of the sections doesn't matter. Also, if you have two sections
with the same name (e.g. \ttt{[General]} occurs twice in the file),
they will be merged.

Lines that start with "\#" are comments, and will be ignored during processing.

Long lines can be broken up using the backslash notation: if the last character
of a line is "\textbackslash", it will be merged with the next line.

There is no limit on the file size or the maximum line length.

Example:

\begin{verbatim}
[General]
# this is a comment
foo="this is a single value \
for the foo parameter"

[General]  # duplicate sections are merged
bar="belongs to the same section as foo"
\end{verbatim}

\subsection{File inclusion}

{\opp} supports including an ini file in another\index{ini file!file inclusion},
via the \ttt{include} keyword. This feature allows you to partition large ini
files into logical units, fixed and varying part etc.

An example:

\begin{verbatim}
# omnetpp.ini
...
include parameters.ini
include per-run-pars.ini
...
\end{verbatim}

You can also include files from other directories. If the included ini file
further includes others, their path names will be understood as relative
to the location of the file which contains the reference,
rather than relative to the current working directory of the simulation.

This rule also applies to other file names occurring in ini files
(such as the \ttt{load-libs=}, \ttt{output-vector-file=}, \ttt{output-scalar-file=}
etc. options, and \ttt{xmldoc()} module parameter values.)


\section{Sections}
\subsection{Overview}

Named configurations are sections of the form \ttt{[Config <configname>]}, where
\textit{<configname>} is by convention a camel-case string that starts with a capital letter:
\ttt{Config1}, \ttt{WirelessPing}, \ttt{OverloadedFifo}, etc. For example,
\ttt{omnetpp.ini} for an Aloha simulation might have the following skeleton:

\begin{Verbatim}[commandchars=\\\{\}]
[General]
...
[Config PureAloha]
...
[Config SlottedAloha1]
...
[Config SlottedAloha2]
...
\end{Verbatim}

Some configuration keys (such as user interface selection) are only
accepted in the \ttt{[General]} section, but most of them can go into Config
sections as well.

When you run a simulation, you need to select one of the configurations
to be activated. In Cmdenv, this is done with the \ttt{-c} command-line option:

\begin{Verbatim}[commandchars=\\\{\}]
$ aloha -c PureAloha
\end{Verbatim}

The simulation will then use the contents of the \ttt{[Config PureAloha]}
section to set up the simulation. (Tkenv, of course, lets you select
the configuration from a dialog.)


\subsection{Fallbacks}

Actually, when you activate the PureAloha configuration, the contents of
the \ttt{[General]} section will also be taken into account: if some
configuration key or parameter value is not found in \ttt{[Config PureAloha]},
then the search will continue in the \ttt{[General]} section. In
other words, lookups in \ttt{[Config PureAloha]} will fall back to \ttt{[General]}.
The \ttt{[General]} section itself is optional; when it is absent, it is
treated like an empty \ttt{[General]} section.

All named configurations fall back to \ttt{[General]} by default. However, for
each configuration it is possible to specify a fall-back section
explicitly, using the extends= key. Consider the following ini file
skeleton:

\begin{Verbatim}[commandchars=\\\{\}]
[General]
...
[Config SlottedAlohaBase]
...
[Config SlottedAloha1]
extends = SlottedAlohaBase
...
[Config SlottedAloha2]
extends = SlottedAlohaBase
...
[Config SlottedAloha2a]
extends = SlottedAloha2
...
[Config SlottedAloha2b]
extends = SlottedAloha2
...
\end{Verbatim}


If you activate the \ttt{SlottedAloha2b} configuration, lookups will consider
sections in the following order (this is also called the
\textit{section fallback chain}): \ttt{SlottedAloha2b},
\ttt{SlottedAloha2}, \ttt{SlottedAlohaBase}, \ttt{General}.

The effect is the same as if the contents of the sections
SlottedAloha2b, SlottedAloha2, SlottedAlohaBase and General were copied
together into one section, one after another, \ttt{[Config SlottedAloha2b]}
being at the top, and \ttt{[General]} at the bottom. Lookups always start at
the top, and stop at the first matching entry.

The concept is similar to inheritance in object-oriented languages,
and benefits are similar too: you can to factor out the common parts of
several configurations into a "base"
configuration, and the other way round, you can reuse existing
configurations (as opposed to copying them) by using them as a base. In
practice you will often have "abstract"
configurations too (in the C++/Java sense), which assign only a subset
of parameters and leave the others open, to be assigned in derived
configurations.

If you are experimenting a lot with different parameter settings of a
simulation model, these techniques will make it a lot easier to manage
ini files.

\section{Scenarios}

\subsection{Basic use}


It is quite common in simulation studies that the simulation model is
run several times with different parameter settings, and the results
are analyzed in relation to the input parameters. OMNeT++ 3.x had no
direct support for batch runs, and users had to resort to writing shell
(or Python, Ruby, etc.) scripts that iterated over the required
parameter space, and generated a (partial) ini file and run the
simulation program in each iteration.

OMNeT++ 4.0 largely automates this process, and eliminates the need for
writing batch execution scripts. It is the ini file where the user can
specify iterations over various parameter settings.
Here's an example:

\begin{Verbatim}[commandchars=\\\{\}]
[Config AlohaScenario]
*.numHosts = \$\{1, 2, 5, 10..50 step 10\}
**.host[*].generationInterval = exponential( \$\{0.2, 0.4, 0.6\} )
\end{Verbatim}


This scenario expands to 8*3 = 24 simulation runs, where the number of
hosts iterates over the numbers 1, 2, 5, 10, 20, 30, 40, 50, and for
each host count three simulation runs will be done, with the generation
interval being exponential(0.2), exponential(0.4), and
exponential(0.6).

How does it get run? First of all, Cmdenv with the '-n' option will tell you how many
simulation runs a given section expands to. (You'll of course use Cmdenv for batch runs,
not Tkenv.)

\begin{Verbatim}[commandchars=\\\{\}]
\$ aloha -u Cmdenv -c AlohaScenario -n

OMNeT++/OMNEST Discrete Event Simulation
...
Config: AlohaScenario
Number of runs: 24
\end{Verbatim}


If you add the '-g' option, the
program will also print out the values of the iteration variables for
each run. Note that the scenario description actually maps to nested
loops, with the last "\$\{..\}" becoming
the innermost loop. The iteration variables are just named \$0 and \$1
-- we'll see that it is possible to give
meaningful names to them. Please ignore the
'\$repetition=0' part in the printout
for now.


\begin{Verbatim}[commandchars=\\\{\}]
\$ aloha -u Cmdenv -c AlohaScenario -n -g
OMNeT++/OMNEST Discrete Event Simulation
...
Config: AlohaScenario
Number of runs: 24
Run 0: \$0=1, \$1=0.2, \$repetition=0
Run 1: \$0=1, \$1=0.4, \$repetition=0
Run 2: \$0=1, \$1=0.6, \$repetition=0
Run 3: \$0=2, \$1=0.2, \$repetition=0
Run 4: \$0=2, \$1=0.4, \$repetition=0
Run 5: \$0=2, \$1=0.6, \$repetition=0
Run 6: \$0=5, \$1=0.2, \$repetition=0
Run 7: \$0=5, \$1=0.4, \$repetition=0
...
Run 19: \$0=40, \$1=0.4, \$repetition=0
Run 20: \$0=40, \$1=0.6, \$repetition=0
Run 21: \$0=50, \$1=0.2, \$repetition=0
Run 22: \$0=50, \$1=0.4, \$repetition=0
Run 23: \$0=50, \$1=0.6, \$repetition=0
\end{Verbatim}


Any of these runs can be executed by passing the '-r
<runnumber>' option to Cmdenv.
So, the task is now to run the simulation program 24 times, with
'-r' running from 0 through 23:

\begin{Verbatim}[commandchars=\\\{\}]
\$ aloha -u Cmdenv -c AlohaScenario -r 0
\$ aloha -u Cmdenv -c AlohaScenario -r 1
\$ aloha -u Cmdenv -c AlohaScenario -r 2
...
\$ aloha -u Cmdenv -c AlohaScenario -r 23
\end{Verbatim}


This batch can be executed either from the OMNeT++ IDE (where you are
prompted to pick an executable and an ini file, choose the scenario
from a list, and just click Run), or using a little command-line
batch execution tool supplied with OMNeT++.

Actually, it is also possible to get Cmdenv execute all runs in one go,
by simply omitting the '-r' option.


\begin{Verbatim}[commandchars=\\\{\}]
\$ aloha -u Cmdenv -c AlohaScenario

OMNeT++/OMNEST Discrete Event Simulation
Preparing for running configuration AlohaScenario, run \#0...
...
Preparing for running configuration AlohaScenario, run \#1...
...
...
Preparing for running configuration AlohaScenario, run \#23...
\end{Verbatim}


However, this approach is not recommended, because it is more
susceptible to C++ programming errors in the model. (For example, if
any of the runs crashes, the whole batch is terminated -- which may
not be what the user wants).

Let us get back to the ini file. We had:

\begin{Verbatim}[commandchars=\\\{\}]
[Config AlohaScenario]
*.numHosts = \$\{1, 2, 5, 10..50 step 10\}
**.host[*].generationInterval = exponential( \$\{0.2, 0.4, 0.6\} )
\end{Verbatim}


The \$\{...\} syntax specifies an iteration. It is sort of a macro: at
each run, the whole \$\{...\} string gets textually replaced with the
current iteration value. The values to iterate over do not need to be
numbers (unless you want to use the \textit{"a..b"} or
\textit{"a..b step c"} syntax), and the
substitution takes place even inside string constants. So, the
following examples are all valid (note that textual substitution is
used):

\begin{Verbatim}[commandchars=\\\{\}]
*.param = 1 + \$\{1e-6, 1/3, sin(0.5)\}
    ==> *.param = 1 + 1e-6
        *.param = 1 + 1/3
        *.param = 1 + sin(0.5)
*.greeting = "We will simulate \$\{1,2,5\} host(s)."
    ==> *.greeting = "We will simulate 1 host(s)."
        *.greeting = "We will simulate 2 host(s)."
        *.greeting = "We will simulate 5 host(s)."
\end{Verbatim}


To write a literal \$\{..\} inside a string constant, quote
"\{" with a backslash, and write "\${\textbackslash}\{..\}".


\subsection{Named iteration variables}

You can assign names to iteration variables, which has the advantage
that you'll see meaningful names instead of \$0 and
\$1 in the Cmdenv output, and also lets you refer to the variables at
more than one place in the ini file. The syntax is
\$\{<varname>=<iteration>\}, and variables can be referred to simply as
\$\{<varname>\}:

\begin{Verbatim}[commandchars=\\\{\}]
[Config Aloha]
*.numHosts = \$\{N=1, 2, 5, 10..50 step 10\}
**.host[*].generationInterval = exponential( \$\{mean=0.2, 0.4, 0.6\} )
**.greeting = "There are \$\{N\} hosts"
\end{Verbatim}

The scope of the variable name is the section that defines it, plus
sections based on that section (via extends=).

There are also a number of predefined variables: \$\{configname\} and
\$\{runnumber\} with the obvious meanings; \$\{network\} is the name of
the network that is simulated; \$\{processid\} and \$\{datetime\}
expand to the OS process id of the simulation and the time it was
started; and there are some more: \$\{runid\}, \$\{iterationvars\} and
\$\{repetition\}.

\$\{runid\} holds the Run ID. When a simulation is run, it gets assigned
a Run ID, which uniquely identifies that instance of running the
simulation: if you run the same thing again, it will get a different
Run ID. Run ID is a concatenation of several variables like
\$\{configname\}, \$\{runnumber\}, \$\{datetime\} and \$\{processid\}.
This yields an identifier that is unique
"enough" for all practical purposes, yet it
is meaningful for humans. The Run ID is recorded into result files
written during the simulation, and can be used to match vectors and
scalars written by the same simulation run.

In cases when not all combinations of the iteration variables make sense
or need to be simulated, it is possible to specify an additional
constraint expression. This expression is interpreted as a conditional
(an "if" statement) within the innermost
loop, and it must evaluate to "true" for
the variable combination to generate a run. The expression should be
given with the constraint= configuration key. An example:

\begin{Verbatim}[commandchars=\\\{\}]
*.numNodes = \$\{n=10..100 step 10\}
**.numNeighbors = \$\{m=2..10 step 2\}
constraint = \$m <= sqrt(\$n)
\end{Verbatim}


The expression syntax supports most C language operators (including
boolean, conditional and binary shift operations) and most
<math.h> functions; data types are boolean,
double and string. The expression must evaluate to a boolean.

\begin{note}
    It is not supported to refer to other iteration variables
    in the definition of an iteration variable (i.e. you cannot write
    things like \$\{j=\$i..10\}), although it might get implemented in
    future OMNeT++ releases.
\end{note}

\subsection{Repeating runs with different seeds}

It is directly supported to perform several runs with the same
parameters but different random number seeds. There are two
configuration keys related to this: repeat= and seed-set=. The first
one simple specifies how many times a run needs to be repeated. For
example,

\begin{Verbatim}[commandchars=\\\{\}]
repeat = 10
\end{Verbatim}

causes every combination of iteration variables to be repeated 10 times,
and the \$\{repetition\} predefined variable holds the loop counter.
Indeed, repeat=10 is equivalent of adding \$\{repetition=0..9\} to the
ini file. The \$\{repetition\} loop always becomes the innermost loop.

The seed-set= configuration key affects seed selection. Every
simulation uses one or more random number generators (as configured by
the num-rngs= key), for which the simulation kernel can automatically
generate seeds. The first simulation run may use one set of seeds (seed
set 0), the second run may use a second set (seed set 1), and so on.
Each set contains as many seeds as there are RNGs configured. All
automatic seeds generate random number sequences that are far apart in
the RNG's cycle, so they will never overlap during
simulations.

\begin{note}
Mersenne Twister, the default RNG of OMNeT++ has a cycle length of
$2^{19937}$, which is more than enough for any conceivable purpose.
\end{note}

The seed-set= key tells the simulation kernel which seed set to use.
It can be set to a concrete number (such as seed-set=0), but it
usually does not make sense as it would cause every simulation to run
with exactly the same seeds. It is more practical to set it to either
\$\{runnumber\} or to \$\{repetition\}. The default setting is
\$\{runnumber\}:

\begin{Verbatim}[commandchars=\\\{\}]
seed-set = \$\{runnumber\}   # this is the default
\end{Verbatim}

This makes every simulation run to execute with a unique seed set. The
second option is:

\begin{Verbatim}[commandchars=\\\{\}]
seed-set = \$\{repetition\}
\end{Verbatim}

where all \$repetition=0 runs will use the same seeds (seed set 0), all
\$repetition=1 runs use another seed set, \$repetition=2 a third seed
set, etc.

To perform runs with manually selected seed sets, you can just define an
iteration for the seed-set= key:

\begin{Verbatim}[commandchars=\\\{\}]
seed-set = \$\{5,6,8..11\}
\end{Verbatim}

In this case, the repeat= key should be left out, as seed-set= already
defines an iteration and there's no need for an extra
loop.

It is of course also possible to manually specify individual seeds for
simulations. This is rarely necessary, but we can use it here to
demonstrate another feature, parallel iterators:

\begin{Verbatim}[commandchars=\\\{\}]
repeat = 4
seed-1-mt = \$\{53542, 45732, 47853, 33434 ! repetition\}
seed-2-mt = \$\{75335, 35463, 24674, 56673 ! repetition\}
seed-3-mt = \$\{34542, 67563, 96433, 23567 ! repetition\}
\end{Verbatim}

The meaning of the above is this: in the first repetition, the first
column of seeds is chosen, for the second repetition, the second
column, etc. The "!" syntax chooses the
\textit{kth} value from the iteration, where \textit{k} is the position
(iteration count) of the iteration variable after the
"!". Thus, the above example is equivalent
to the following:

\begin{Verbatim}[commandchars=\\\{\}]
# no repeat= line!
seed-1-mt = \$\{seed1 = 53542, 45732, 47853, 33434\}
seed-2-mt = \$\{        75335, 35463, 24674, 56673 ! seed1\}
seed-3-mt = \$\{        34542, 67563, 96433, 23567 ! seed1\}
\end{Verbatim}

That is, the iterators of seed-2-mt and seed-3-mt are advanced
in lockstep with the seed1 iteration.


\section{Scenarios and Result Analysis}

\subsection{Output vectors and scalars}

In OMNeT++ 3.x, the default result file names were ``omnetpp.vec'' and
``omnetpp.sca''. This is not very convenient for batch execution, where
an output vector file created in one run would be overwritten in the
next run. Thus, we have changed the default file names to make them
differ for every run. The new defaults are:

\begin{Verbatim}[commandchars=\\\{\}]
output-vector-file = "\$\{configname\}-\$\{runnumber\}.vec"
output-scalar-file = "\$\{configname\}-\$\{runnumber\}.sca"
\end{Verbatim}


This generates file names like "PureAloha-0.vec", "PureAloha-1.vec", and so on.

Also, in OMNeT++ 3.x output scalar files were always appended to by the
simulation program, rather than being overwritten. This behavior was
changed in 4.0 to make it consistent with vector files, that is, output
scalar files are also overwritten by the simulator, and not appended
to.

\begin{note}
    The old behavior can be turned back on by setting
    output-scalar-file-append=true.
\end{note}

The way of configuring output vectors has also changed. In OMNeT++ 3.x,
the keys for enabling-disabling a vector and specifying recording
interval were <module-and-vectorname-pattern>.enabled,
and <module-and-vectorname-pattern>.interval.
The "enabled" and "interval" words changed to "enable-recording" and
"recording-interval".

\begin{note}
    The reason for this change is that per-object
    configuration keys are now required to have a hyphen in their names, to
    make it possible to tell them apart from module parameter assignments.
    This allows the simulator to catch mistyped config keys in ini files.
\end{note}

The syntax for specifying the recording interval has also been extended
(in a backward compatible way) to accept multiple intervals, separated
by comma. An example:

\begin{Verbatim}[commandchars=\\\{\}]
**.fifo[2].queueLengthVector.enable-recording = false
**.fifo[*].queueLengthVector.recording-interval = ..100, 300..500, 900..
\end{Verbatim}

Although it has nothing to do with our main topic (ini files), this is a
good place to mention that the format of result files have been
extended to include meta info such as the run ID, network name, all
configuration settings, etc. These data make the files more
self-documenting, which can be valuable during the result analysis
phase, and increase reproduciblity of the results. Another change is
that vector data are now recorded into the file clustered by the output
vectors, which (combined with index files) allows much more efficient
processing.

\subsection{Saving parameters as scalars}

When you are running several simulations with different parameter
settings, you'll usually want to refer to selected
input parameters in the result analysis as well -- for example when
drawing a throughput (or response time) versus load (or network
background traffic) plot. Average throughput or response time numbers
are saved into the output scalar files, and it is useful for the input
parameters to get saved into the same file as well.

For convenience, OMNeT++ automatically saves the iteration variables
into the output scalar file, so they can be referred to during result
analysis. Module parameters can also be saved, but this has to be
requested by the user, by configuring save-as-scalar=true for the
parameters in question. The configuration key is a pattern that
identifies the parameter, plus ".save-as-scalar". An example:

\begin{Verbatim}[commandchars=\\\{\}]
**.host[*].networkLoad.save-as-scalar = true
\end{Verbatim}

This looks simple enough. However, there are three pitfalls:
non-numeric parameters, too many matching parameters, and
random-valued volatile parameters.

First, the scalar file only holds numeric results, so non-numeric
parameters cannot be recorded -- that will result in a runtime
error.

Second, if wildcards in the pattern match too many parameters, that
might unnecessarily increase the size of the scalar file. For example,
if the host[] module vector size is 1000 in the example below, then the
same value (3) will be saved 1000 times into the scalar file, once for
each host.

\begin{Verbatim}[commandchars=\\\{\}]
**.host[*].startTime = 3
**.host[*].startTime.save-as-scalar = true  \# saves "3" once for each host
\end{Verbatim}

Third, recording a random-valued volatile parameter will just save a
random number from that distribution. This is rarely what you need, and
the simulation kernel will also issue a warning if this happens.

\begin{Verbatim}[commandchars=\\\{\}]
**.interarrivalTime = exponential(1)
**.interarrivalTime.save-as-scalar = true  \# wrong: saves random values!
\end{Verbatim}


These pitfalls are not rare in practice, so it is usually more
convenient to rely on the iteration variables in the result analysis.
That is, one can rewrite the above example as

\begin{Verbatim}[commandchars=\\\{\}]
**.interarrivalTime = exponential( ${mean=1} )
\end{Verbatim}

and refer to the \$mean iteration variable instead of the
interarrivalTime module parameter(s) during result analysis.
save-as-scalar=true is not needed because iteration variables are
automatically saved into the result files.



\subsection{Experiment-Measurement-Replication}

We have introduced three concepts that are useful for organizing
simulation results generated by batch executions or several batches of
executions.

During a simulation study, a person prepares several
\textit{experiments}. The purpose of an experiment is to find out the
answer to questions like \textit{"how does the number of
nodes affect response times in the network?"} For an
experiment, several \textit{measurements} are performed on the
simulation model, and each measurement runs the simulation model with a
different parameter settings. To eliminate the bias introduced by the
particular random number stream used for the simulation, several
\textit{replications} of every measurement are run with different
random number seeds, and the results are averaged.

OMNeT++ result analysis tools can take advantage of
experiment/measurement/replication labels recorded into result files,
and organize simulation runs and recorded output scalars and vectors
accordingly on the user interface.

These labels can be explicitly specified in the ini file using the
experiment=, measurement= and replication= config keys. If they are
missing, the default is the following:

\begin{Verbatim}[commandchars=\\\{\}]
experiment = "\$\{configname\}"
measurement = "\$\{iterationvars\}"
replication = "\#\$\{repetition\},seed-set=<seedset>"
\end{Verbatim}


That is, the default experiment label is the configuration name; the
measurement label is concatenated from the iteration variables; and the
replication label contains the repeat loop variable and for the
seed-set. Thus, for our first example the
experiment-measurement-replication tree would look like this:

\begin{Verbatim}[commandchars=\\\{\}]
\textrm{"PureAloha" }\textrm{\textit{--experiment}}
\textrm{\$N=1,\$mean=0.2}\textrm{\textit{ -- measurement}}
\textrm{\#0, seed-set=0}\textrm{\textit{ -- replication}}
\end{Verbatim}

\#1, seed-set=1

\#2, seed-set=2

\#3, seed-set=3

\#4, seed-set=4

\$N=1,\$mean=0.4

\#0, seed-set=5

\#1, seed-set=6

...

\#4, seed-set=9

\$N=1,\$mean=0.6

\#0, seed-set=10

\#1, seed-set=11

...

\#4, seed-set=14

\$N=2,\$mean=0.2

...

\$N=2,\$mean=0.4

...

...




The experiment-measurement-replication labels should be enough to
reproduce the same simulation results, given of course that the ini
files and the model (NED files and C++ code) haven't
changed.

Every instance of running the simulation gets a unique run ID. We can
illustrate this by listing the corresponding run IDs under each
repetition in the tree. For example:

"PureAloha"

\$N=1,\$mean=0.2

\#0, seed-set=0

\textit{PureAloha-0-20070704-11:38:21-3241}

\textit{PureAloha-0-20070704-11:53:47-3884}

\textit{PureAloha-0-20070704-16:50:44-4612}

\#1, seed-set=1

\textit{PureAloha-1-20070704-16:50:55-4613}

\#2, seed-set=2

\textit{PureAloha-2-20070704-11:55:23-3892}

\textit{PureAloha-2-20070704-16:51:17-4615}

{\itshape
{\dots}}




The tree shows that ("PureAloha", "\$N=1,\$mean=0.2", "\#0, seed-set=0")
was run three times. The results produced
by these three executions should be identical, unless, for example,
some parameter was modified in the ini file, or a bug got fixed in the
C++ code.

We believe that the default way of generating
experiment-measurement-replication labels will be useful and
sufficient in the majority of the simulation studies. However, you can
customize it if needed. For example, here is a way to join two
scenarios into one experiment:

\begin{Verbatim}[commandchars=\\\{\}]
[Config PureAloha\_Part1]
experiment = "PureAloha"
...
[Config PureAloha\_Part2]
experiment = "PureAloha"
...
\end{Verbatim}




Measurement and replication labels can be customized in a similar way,
making use of named iteration variables, \$\{repetition\},
\$\{runnumber\} and other predefined variables. One possible benefit is
to customize the generated measurement and replication labels. For
example:

\begin{Verbatim}[commandchars=\\\{\}]
[Config PureAloha\_Part1]
measurement = "\$\{N\} hosts, exponential(\$\{mean\}) packet generation interval"
\end{Verbatim}


One should be careful with the above technique though, because if some
iteration variables are left out of the measurement labels, runs with
all values of those variables will be grouped together to the same
replications.



////////////////////////////////////////////////////////////////





\section{User interfaces}

{\opp} simulations can be run under different user interfaces.
Currenly, two user interfaces are supported:

\begin{itemize}
  \item Tkenv: Tcl/Tk-based graphical, windowing user interface
  \item Cmdenv: command-line user interface for batch execution
\end{itemize}


You would typically test and debug your simulation under Tkenv,
then run actual simulation experiments from the command line or
shell script, using Cmdenv. Tkenv is also better suited for educational or
demonstration purposes.

Both Tkenv and Cmdenv are provided in the form of a library, and
you choose between them by linking one or the other into your
simulation executable. (Creating the executable was described in
chapter \ref{cha:building-simulation-programs}). Both user interfaces
are supported on Unix and Windows platforms.

Common functionality in Tkenv and Cmdenv has been collected and
placed into the Envir library\index{Envir}, which can be thought of as the
``common base class'' for the two user interfaces.

The user interface\index{user interface} is separated from the
simulation kernel, and the two parts interact through a well-defined
interface. This also means that, if needed, you can write your
own user interface or embed an {\opp} simulation into your application
without any change to models or the simulation library.



\subsection{The [General] section}

The most important options of the \texttt{[General]} section are the
following.
\begin{itemize}
  \item{The \fpar{network} option selects the model to be set up and run.}
  \item{The length of the simulation can be set with the
    \fpar{sim-time-limit} and the \fpar{cpu-time-limit} options (the
    usual time units such as ms, s, m, h, etc. can be used).}
  \item{The output file names can be set with the following options:
    \fpar{output-vector-file}, \fpar{output-scalar-file} and \fpar{snapshot-file}.}
\end{itemize}

It is important to note, that the loaded NED files may contain
any number of modules, channel and \textit{any number of networks} as well.
It does not matter whether you use all or just some of them
in the simulations. You will be able to select \ttt{any} of the
networks that occur in the loaded NED files using the \ttt{network=}
\ttt{omnetpp.ini} entry, and as long as every module, channel etc
for it has been loaded, network setup will be successful.


\section{Setting module parameters in omnetpp.ini}
\label{sec:ch-run-sim:parameter-settings}

Simulations get input via module parameters, which can be assigned a
value in NED files or in \ttt{omnetpp.ini} -- in this order. Since parameters
assigned in NED files cannot be overridden in omnetpp.ini, one can
think about them as being ``hardcoded''. In contrast, it is easier
and more flexible to maintain module parameter settings in omnetpp.ini.

In omnetpp.ini, module parameters are referred to by their full paths
or hiearchical names. This name consists of the dot-separated list of
the module names (from the top-level module down to the module containg
the parameter), plus the parameter name
(see section \ref{sec:sim-lib:fullname-and-fullpath}).

An example \ttt{omnetpp.ini} which sets the \ttt{numHosts} parameter of
the toplevel module and the \ttt{transactionsPerSecond} parameter of the
\ttt{server} module:

\begin{verbatim}
[Parameters]
net.numHosts = 15
net.server.transactionsPerSecond = 100
\end{verbatim}


\subsection{Using wildcard patterns}
\label{sec:ch-run-sim:wildcards}

Models can have a large number of parameters to be configured, and it would
be tedious to set them one-by-one in \ttt{omnetpp.ini}. {\opp} supports
\textit{wildcards patterns} which allow for setting several model parameters
at once.

The notation is a variation on the usual glob-style patterns.
The most apperent differences to the usual rules are the distinction between
\ttt{*} and \ttt{**}, and that character ranges should be written
with curly braces instead of square brackets (that is, \textit{any-letter}
is \ttt{\{a-zA-Z\}} not \ttt{[a-zA-Z]}, because square brackets are
already reserved for the notation of module vector indices).

Pattern syntax:

\begin{itemize}
  \item \ttt{?} : matches any character except dot (.)
  \item \ttt{*} : matches zero or more characters except dot (.)
  \item \ttt{**} : matches zero or more character (any character)
  \item \ttt{\{a-f\}} : \textit{set}: matches a character in the range a-f
  \item \ttt{\{{\textasciicircum}a-f\}}: \textit{negated set}: matches a character
    NOT in the range a-f
  \item \ttt{\{38..150\}} : \textit{numeric range}: any number (i.e. sequence of digits)
    in the range 38..150  (e.g. \ttt{99})
  \item \ttt{[38..150]} : \textit{index range}: any number in square brackets in the
    range 38..150 (e.g. \ttt{[99]})
  \item backslash ({\textbackslash}) : takes away the special meaning of the
    subsequent character
\end{itemize}

\subsubsection{Precedence}

If you use wildcards, the order of entries is important: if a parameter
name matches several wildcards-patterns, the \textit{first} matching occurrence
is used. This means that you need to list specific settings first, and
more general ones later. Catch-all settings should come last.

An example ini file:

\begin{verbatim}
[Parameters]
*.host[0].waitTime = 5ms   # specifics come first
*.host[3].waitTime = 6ms
*.host[*].waitTime = 10ms  # catch-all comes last
\end{verbatim}


\subsubsection{Asterisk vs double asterisk}

The \ttt{*} wildcard is for matching a single module or parameter name in the
path name, while \ttt{**} can be used to match several components in the path.
For example, \ttt{**.queue*.bufSize} matches the \ttt{bufSize} parameter of any module
whose name begins with \ttt{queue} in the model, while \ttt{*.queue*.bufSize}
or \ttt{net.queue*.bufSize} selects only queues immediately on network level.
Also note that \ttt{**.queue**.bufSize} would match \ttt{net.queue1.foo.bar.bufSize}
as well!

\subsubsection{Sets, negated sets}

Sets and negated sets can contain several character ranges and also
enumeration of characters. For example, \ttt{\{\_a-zA-Z0-9\}} matches any letter
or digit, plus the underscore; \ttt{\{xyzc-f\}} matches any of the characters
x, y, z, c, d, e, f.
To include '-' in the set, put it at a position where it cannot be
interpreted as character range, for example: \ttt{\{a-z-\}} or \ttt{\{-a-z\}}.
If you want to include '\}' in the set, it must be the first
character: \ttt{\{\}a-z\}}, or as a negated set: \ttt{\{{\textasciicircum}\}a-z\}}. A backslash
is always taken as literal backslash (and NOT as escape character)
within set definitions.


\subsubsection{Numeric ranges and index ranges}

Only nonnegative integers can be matched.  The start or the end of the range
(or both) can be omitted: \ttt{\{10..\}}, \ttt{\{..99\}} or \ttt{\{..\}}
are valid numeric ranges (the last one matches any number).
The specification must use exactly two dots.
Caveat: \ttt{*\{17..19\}} will match \ttt{a17}, \ttt{117} and \ttt{963217} as well,
because the \ttt{*} can also match digits!

An example for numeric ranges:

\begin{verbatim}
[Parameters]
*.*.queue[3..5].bufSize = 10
*.*.queue[12..].bufSize = 18
*.*.queue[*].bufSize = 6  # this will only affect queues 0,1,2 and 6..11
\end{verbatim}


\subsection{Applying the defaults}

It is also possible to utilize the default values specifified with
\ttt{input(}\textit{default-value}\ttt{)} in the NED files.
The \textit{<parameter-name>}\ttt{.use-default=yes} setting assigns
the default value to the parameter, or 0, false or empty string if
there was no default value in the NED file.

The following example sets \ttt{ttl} (time-to-live) of \ttt{hostA}'s
\ttt{ip} module to 5, while all other nodes in the network
will get the default specified with \ttt{input()} in the NED files.

\begin{Verbatim}[commandchars=\\\{\}]
[Parameters]
**.hostA.ip.ttl = 5
**.ip.ttl.use-default = yes
\end{Verbatim}

To make use of \textit{all} defaults in NED files, you'd add the following to
\ttt{omnetpp.ini}:

\begin{verbatim}
[Parameters]
**.use-default = yes
\end{verbatim}


\section{Configuring output vectors}
\label{sec:ch-run-sim:outvectors}

As a simulation program is evolving, it is becoming capable of
collecting more and more statistics. The size of output vector
files\index{output!vector file} can easily reach a magnitude of
several ten or hundred megabytes, but very often, only some of the
recorded statistics are interesting to the analyst.

In {\opp}, you can control how \cclass{cOutVector} objects record data
to disk. You can turn output vectors on/off or you can assign a result
collection interval. Output vector configuration is given in the
\texttt{[OutVectors]} section of the ini file, or in the \texttt{[Run
  1]}, \texttt{[Run 2]} etc sections individually for each run. By
default, all output vectors are turned on.

Output vectors can be configured with the following syntax:

\begin{Verbatim}[commandchars=\\\{\}]
\textit{module-pathname}.\textit{objectname}.enabled = yes/no
\textit{module-pathname}.\textit{objectname}.interval = \textit{start}..\textit{stop}
\textit{module-pathname}.\textit{objectname}.interval = ..\textit{stop}
\textit{module-pathname}.\textit{objectname}.interval = \textit{start}..
\end{Verbatim}

The object name is the string passed to \cclass{cOutVector} in its constructor
or with the \fname{setName()} member function.

\begin{verbatim}
cOutVector eed("End-to-End Delay");
\end{verbatim}

Start and stop values can be any time specification accepted
in NED and config files (e.g. \textit{10h 30m 45.2s}).

As with parameter names, wildcards are allowed in the object
names and module path names.

An example:

\begin{verbatim}
#
# omnetpp.ini
#

[OutVectors]
**.interval = 1s..60s
**.End-to-End Delay.enabled = yes
**.Router2.**.enabled = yes
**.enabled = no
\end{verbatim}


The above configuration limits collection of all output vectors
to the 1s..60s interval, and disables collection of output vectors
except all end-to-end delays and the ones in any module called Router2.


\section{Configuring the random number generators}
\label{sec:ch-run-sim:rng-config}

The random number architecture of {\opp} was already outlined
in section \ref{cha:sim-lib:generating-random-numbers}. Here
we'll cover the configuration of RNGs in \ttt{omnetpp.ini}.

\subsection{Number of RNGs}

The \ttt{num-rngs=} configuration entry sets the number of
random number generator instances (i.e. random number streams)
available for the simulation model (see \ref{cha:sim-lib:generating-random-numbers}).
Referencing an RNG number greater or equal to this number
(from a simple module or NED file) will cause a runtime error.


\subsection{RNG choice}

The \ttt{rng-class=} configuration entry sets the random number
generator class to be used. It defaults to \ttt{"cMersenneTwister"},
the Mersenne Twister RNG. Other available classes are \ttt{"cLCG32"}
(the "legacy" RNG of {\opp} 2.3 and earlier versions, with a cycle length
of $2^{31}-2$), and \ttt{"cAkaroaRNG"} (Akaroa's random number generator,
see section \ref{sec:ch-run-sim:akaroa}).

\subsection{RNG mapping}

The RNG numbers used in simple modules may be arbitrarily mapped to the
actual random number streams (actual RNG instances) from \ttt{omnetpp.ini}.
The mapping allows for great flexibility in RNG usage and random number
streams configuration -- even for simulation models which were not
written with RNG awareness.

RNG mapping may be specified in \ttt{omnetpp.ini}. The syntax of
configuration entries is the following.

\begin{verbatim}
[General]
<modulepath>.rng-N=M  (where N,M are numeric, M<num-rngs)
\end{verbatim}

This maps module-local RNG N to physical RNG M. The following
example maps all  \ttt{gen} module's default (N=0) RNG to physical RNG 1,
and all  \ttt{noisychannel} module's default (N=0) RNG to physical RNG 2.

\begin{verbatim}
[General]
num-rngs = 3
**.gen[*].rng-0 = 1
**.noisychannel[*].rng-0 = 2
\end{verbatim}

This mapping allows variance reduction techniques to be applied to
{\opp} models, without any model change or recompilation.


\subsection{Automatic seed selection}

Automatic seed selection gets used for an RNG if you don't explicitly
specify seeds in omnetpp.ini. Automatic and manual seed selection can
co-exist: for a particular simulation, some RNGs can be configured
manually, and some automatically.

The automatic seed selection mechanism uses two inputs: the \textit{run number}
(i.e. the number in the \ttt{[Run 1]}, \ttt{[Run 2]}, etc. section names),
and the \textit{RNG number}. For the same the run number and RNG number,
{\opp} always selects the same seed value for any simulation model.
If the run number or the RNG number is different, {\opp} does its best
to choose different seeds which are also sufficiently apart in the RNG's sequence
so that the generated sequences don't overlap.

The run number can be specified either in in omnetpp.ini (e.g. via the
\ttt{[Cmdenv]/runs-to-execute=} entry) or on the command line:

\begin{verbatim}
./mysim -r 1
./mysim -r 2
./mysim -r 3
\end{verbatim}

For the \ttt{cMersenneTwister} random number generator, selecting seeds
so that the generated sequences don't overlap is easy,
due to the extremely long sequence of the RNG.
The RNG is initialized from the 32-bit seed value $seed = runNumber*numRngs + rngNumber$.
(This implies that simulation runs participating in the study should have
the same number of RNGs set).
    \footnote{While (to our knowledge) no one has proven that the seeds 0,1,2,...
    are well apart in the sequence, this is probably true, due to the extremely
    long sequence of MT. The author would however be interested in papers
    published about seed selection for MT.}

For the \ttt{cLCG32} random number generator, the situation is more difficult,
because the range of this RNG is rather short ($2^{31}-1$, about 2 billion).
For this RNG, {\opp} uses a table of 256 pre-generated seeds, equally spaced
in the RNG's sequence. Index into the table is calculated with the
$runNumber*numRngs + rngNumber$ formula. Care should be taken that
one doesn't exceed 256 with the index, or it will wrap and the
same seeds will be used again. It is best not to use the \ttt{cLCG32}
at all -- \ttt{cMersenneTwister} is superior in every respect.


\subsection{Manual seed configuration}

In some cases you may want manually configure seed values.
Reasons for doing that may be that you want to use variance reduction
techniques, or you may want to use the same seeds for several simulation
runs.

For the cLCG32 RNG, {\opp} provides a standalone program to generate
seed values (\fprog{seedtool} is discussed in section
\ref{sec:ch-run-sim:seedtool}), and you can specify those seeds explicitly
in the ini file.

The following ini file explicitly initializes two of the random
number generators, and uses different seed values for each run:

\begin{verbatim}
[General]
rng-class=cLCG32  # needed because the default is cMersenneTwister
num-rngs = 2

[Run 1]
seed-0-lcg32 = 1768507984
seed-1-lcg32 = 33648008

[Run 2]
seed-0-lcg32 = 1082809519
seed-1-lcg32 = 703931312
...
\end{verbatim}

To manually set seeds for the Mersenne Twister RNG (which should
seldom, if ever, be necessary), use the \ttt{seed-0-mt=},
\ttt{seed-1-mt=}, etc settings:

\begin{verbatim}
[General]
num-rngs = 2

[Run 1]
seed-0-mt = 1317366363
seed-1-mt = 1453732904

[Run 2]
...
\end{verbatim}

To set a seed value for all runs, place the necessary seed entries
into the \ttt{[General]} section.


\subsection{Choosing good seed values: the seedtool utility}
\label{sec:ch-run-sim:seedtool}

The \fprog{seedtool} program can be used for selecting
seeds for the cLCG32 RNG. When started without command-line
arguments, the program prints out the following help:

\begin{verbatim}
seedtool - part of OMNeT++/OMNEST, (C) 1992-2004 Andras Varga
See the license for distribution terms and warranty disclaimer.

Generates seeds for the LCG32 random number generator. This RNG has a
period length of 2^31-2, which makes about 2,147 million random numbers.
Note that Mersenne Twister is also available in OMNeT++, which has a
practically infinite period length (2^19937).

Usage:
  seedtool i seed         - index of 'seed' in cycle
  seedtool s index        - seed at index 'index' in cycle
  seedtool d seed1 seed2  - distance of 'seed1' and 'seed2' in cycle
  seedtool g seed0 dist   - generate seed 'dist' away from 'seed0'
  seedtool g seed0 dist n - generate 'n' seeds 'dist' apart, starting at 'seed0'
  seedtool t              - generate hashtable
  seedtool p              - print hashtable
\end{verbatim}


The last two options, p and t were used internally to generate
a hash table of pre-computed seeds that greatly speeds up the
tool. For practical use, the g option is the most important.
Suppose you have 4 simulation runs that need two independent
random number generators each and you want to start their seeds
at least 10,000,000 values apart. The first seed value can be
simply 1. You would type the following command:

\begin{verbatim}
C:\OMNETPP\UTILS> seedtool g 1 10000000 8
\end{verbatim}


The program outputs 8 numbers that can be used as random number
seeds:

\begin{verbatim}
1768507984
33648008
1082809519
703931312
1856610745
784675296
426676692
1100642647
\end{verbatim}


You would specify these seed values in the ini file.



\section{Cmdenv: the command-line interface}

The command line user interface\index{command line user interface} is
a small, portable and fast user interface that compiles and runs on
all platforms. Cmdenv\index{Cmdenv} is designed primarily for batch execution.

Cmdenv uses simply executes some or all simulation runs that are described
in the configuration file. If one run stops with an error message,
subsequent ones will still be executed. The runs to be executed can be
passed via command-line argument or in the ini file.

\subsection{Command-line switches}

A simulation program built with Cmdenv accepts the following command line
switches\index{command line switches}:

\begin{longtable}{lp{12cm}}
  \ttt{-h}
  &
  The program prints a short help message and the networks
  contained in the executable, then exits.\\

  \ttt{-f} \texttt{<}\textit{fileName\texttt{>}}
  &
  Specify the name of the configuration file.
  The default is \texttt{omnetpp.ini}\index{omnetpp.ini}.
  Multiple \ttt{-f} switches can be given; this allows you to partition your
  configuration file.  For example, one file can contain your general
  settings, another one most of the module parameters, another one the
  module parameters you change often.\\

  \ttt{-l} \texttt{<}\textit{fileName\texttt{>}}
  &
  Load a shared object\index{shared objects} (\texttt{.so} file on Unix).
  Multiple \ttt{-l} switches are accepted. Your \texttt{.so} files may contain module
  code etc. By dynamically loading all simple
  module code and compiled network description (\texttt{\_n.o} files
  on Unix) you can even eliminate the need to re-link the simulation
  program after each change in a source file.  (Shared objects can be
  created with \texttt{gcc -shared...})\\

  \ttt{-r} \texttt{<}\textit{runs\texttt{>}}
  &
  It specifies which runs should be executed (e.g. \ttt{-r 2,4,6-8}).
  This option overrides the \texttt{runs-to-execute=} option
  in the \texttt{[Cmdenv]} section of the ini file\index{ini file}
  (see later).\\
\end{longtable}

All other options are read from the configuration file.

An example of running an {\opp} executable with the -h flag:

\begin{verbatim}
% ./fddi -h

OMNeT++/OMNEST Discrete Event Simulation  (C) 1992-2005 Andras Varga
See the license for distribution terms and warranty disclaimer
Setting up Tkenv...

Command line options:
  -h            Print this help and exit.
  -f <inifile>  Use the given ini file instead of omnetpp.ini. Multiple
                -f options are accepted to load several ini files.
  -u <ui>       Selects the user interface. Standard choices are Cmdenv
                and Tkenv. To make a user interface available, you need
                to link the simulation executable with the cmdenv/tkenv
                library, or load it as shared library via the -l option.
  -l <library>  Load the specified shared library (.so or .dll) on startup.
                The file name should be given without the .so or .dll suffix
                (it will be appended automatically.) The loaded module may
                contain simple modules, plugins, etc. Multiple -l options
                can be present.

Tkenv-specific options:
  -r <run>      Set up the given run, specified in a [Run n] section of
                the ini file.

The following components are available:
  module types:
    FDDI_Monitor
    FDDI_Generator4Sniffer
    FDDI_Generator4Ring
    ...

End run of OMNeT++
\end{verbatim}


\subsection{Cmdenv ini file options}
\label{sec:ch-run-sim:cmdenv-section}

Cmdenv can be executed in two modes, selected by the \ttt{express-mode} ini file entry:

\begin{itemize}
    \item \tbf{Normal} (non-express) mode is for debugging: detailed information
        will be written to the standard output (event banners, module output,
        etc).
    \item \tbf{Express} mode can be used for long simulation runs: only
        periodical status update is displayed about the progress of the
        simulation.
\end{itemize}

The full list of ini file options recognized by Cmdenv:

\begin{longtable}{|p{6.5cm}|p{7.5cm}|}
\hline
\tabheadcol
\tbf{Entry and default value} & \tbf{Description}\\\hline
\multicolumn{2}{|l|}{\tbf{[Cmdenv]}}\\\hline
%%
\fpar{runs-to-execute} = & Specifies which simulation runs should be executed.
It accepts a comma-separated list of run numbers or run number ranges, e.g.
\ttt{1,3-4,7-9}. If the value is missing, Cmdenv executes all runs that have
ini file sections; if no runs are specified in the ini file, Cmdenv does one run.
The -r command line option overrides this ini file setting. \\\hline
%%
\fpar{express-mode}=yes/no (default: no) & Selects ``normal'' (debug/trace) or ``express'' mode.
\\\hline
%%
\fpar{module-messages}=yes/no (default: yes) & In normal mode only:
printing module ev<< output on/off \\\hline
%%
\fpar{event-banners}=yes/no (default: yes) & In normal mode only:
printing event banners on/off \\\hline
%%
\fpar{message-trace}=yes/no (default: no) & In normal mode only: print a line
about each message sending (by \fname{send()},\fname{scheduleAt()}, etc)
and delivery on the standard output \\\hline
%%
\fpar{autoflush}=yes/no (default: no) &  Call \fname{fflush(stdout)} after each
event banner or status update; affects both express and normal mode. Turning on
autoflush can be useful with printf-style debugging for tracking down
program crashes. \\\hline
%%
\fpar{status-frequency}=<integer> (default: 50000) & In express mode only:
print status update every n events (on today's computers, and
for a typical model, this will produce an update every few seconds,
perhaps a few times per second) \\\hline
%%
\fpar{performance-display}=yes/no (default: yes) & In express mode only:
print detailed performance information. Turning it on results in a 3-line
entry printed on each update, containing ev/sec, simsec/sec, ev/simsec,
number of messages created/still present/currently scheduled in FES\index{FES}.
\\\hline
%%
\fpar{extra-stack-kb} = 8 & Specifies the extra amount of stack
(in kilobytes) that is reserved for each \fname{activity()}
simple module when the simulation is run under Cmdenv.\\\hline
\end{longtable}


\subsection{Interpreting Cmdenv output}
\label{sec:ch-run-sim:interpreting-cmdenv-output}

When the simulation is running in ``express'' mode with detailed
performance display enabled, Cmdenv periodically outputs a three-line
status info about the progress of the simulation.
The output looks like this:

\begin{verbatim}
...
** Event #250000   T=123.74354 ( 2m  3s)    Elapsed: 0m 12s
     Speed:     ev/sec=19731.6   simsec/sec=9.80713   ev/simsec=2011.97
     Messages:  created: 55532   present: 6553   in FES: 8
** Event #300000   T=148.55496 ( 2m 28s)    Elapsed: 0m 15s
     Speed:     ev/sec=19584.8   simsec/sec=9.64698   ev/simsec=2030.15
     Messages:  created: 66605   present: 7815   in FES: 7
...
\end{verbatim}

The first line of the status display (beginning with \ttt{**})
contains:

\begin{itemize}
   \item{how many events have been processed so far}
   \item{the current simulation time (T), and}
   \item{the elapsed time (wall clock time) since the beginning of the simulation run.}
\end{itemize}

The second line displays info about simulation performance:

\begin{itemize}
   \item{\ttt{ev/sec} indicates \textit{performance}: how many events are processed
     in one real-time second.  On one hand it depends on your hardware
     (faster CPUs process more events per second), and on the other hand
     it depends on the complexity (amount of calculations) associated
     with processing one event. For example, protocol simulations tend to require
     more processing per event than e.g. queueing networks, thus
     the latter produce higher ev/sec values.
     In any case, this value is independent of the size (number of modules) in your model.}
   \item{\ttt{simsec/sec} shows \textit{relative speed} of the simulation, that is,
     how fast the simulation is progressing compared to real time, how many
     simulated seconds can be done in one real second. This value virtuall depends
     on everything: on the hardware, on the size of the simulation model,
     on the complexity of events, and the average simulation time between events as well.}
   \item{\ttt{ev/simsec} is the \textit{event density}: how many events are
     there per simulated second. Event density only depends on the simulation model,
     regardless of the hardware used to simulate it: in a cell-level ATM simulation
     you'll have very hight values ($10^9$), while in a bank teller simulation
     this value is probably well under 1. It also depends on the size of your
     model: if you double the number of modules in your model, you can expect
     the event density double, too.}
\end{itemize}

The third line displays the number of messages, and it is important
because it may indicate the `health' of your simulation.

\begin{itemize}
   \item{\ttt{Created}: total number of message objects created since the
     beginning of the simulation run. This does not mean that this many message
     object actually exist, because some (many) of them may have been deleted
     since then. It also does not mean that \textit{you} created all those
     messages -- the simulation kernel also creates messages for its own use
     (e.g. to implement \ttt{wait()} in an \ttt{activity()} simple module).}
   \item{\ttt{Present}: the number of message objects currently present
     in the simulation model, that is, the number of messages created (see above)
     minus the number of messages already deleted. This number includes
     the messages in the FES\index{FES}.}
   \item{\ttt{In FES}: the number of messages currently scheduled in the
     Future Event Set.}
\end{itemize}


The second value, the number of messages present is more useful than
perhaps one would initially think. It can indicator of the `health' of the simulation:
if it is growing steadily, then either you have a memory leak and losing
messages (which indicates a programming error), or the network you simulate is
overloaded and queues are steadily filling up (which might indicate wrong input
parameters).

Of course, if the number of messages does not increase, it does not mean
that you do \textit{not} have a memory leak (other memory leaks are also
possible). Nevertheless the value is still useful, because by far the
most common way of leaking memory in a simulation is by not deleting messages.



\section{Tkenv: the graphical user interface}

\subsubsection{Features}

Tkenv\index{Tkenv} is a portable graphical windowing user interface.
Tkenv supports interactive execution of the simulation, tracing and
debugging\index{simulation!debugging}. Tkenv is recommended in the
development stage of a simulation or for presentation and educational
purposes, since it allows one to get a detailed picture of the state
of simulation at any point of execution and to follow what happens
inside the network.

\subsection{Command-line switches}

A simulation program built with Tkenv accepts the following command line
switches\index{command line switches}:

\begin{longtable}{lp{12cm}}
  \ttt{-h}
  &
  The program prints a short help message and the networks
  contained in the executable, then exits.\\

  \ttt{-f }\textit{<fileName>}
  &
  Specify the name of the configuration file.
  The default is \texttt{omnetpp.ini}\index{omnetpp.ini}.
  Multiple \ttt{-f} switches can be given; this allows you to partition your
  configuration file.  For example, one file can contain your general
  settings, another one most of the module parameters, another one the
  module parameters you change often.\\

  \ttt{-l }\textit{<fileName>}
  &
  Load a shared object\index{shared objects} (\texttt{.so} file on Unix).
  Multiple \ttt{-l} switches are accepted. Your \texttt{.so} files may contain module
  code etc. By dynamically loading all simple
  module code and compiled network description (\texttt{\_n.o} files
  on Unix) you can even eliminate the need to re-link the simulation
  program after each change in a source file.  (Shared objects can be
  created with \texttt{gcc -shared...})\\

  \ttt{-r }\textit{<run-number>}
  &
  It has the same effect as (but takes priority over) the \ttt{[Tkenv]/default-run=}
  ini file entry.

\end{longtable}

\subsection{In Memoriam\dots }

There used to be other windowing user interfaces which have been removed
from the distribution:

\begin{itemize}
  \item \tbf{TVEnv}. A Turbo Vision-based user interface, the first
    interactive UI for {\opp}. Turbo Vision was an excellent
    character-graphical windowing environment, originally shipped with
    Borland C++ 3.1.
  \item \tbf{XEnv}. A GUI written in pure X/Motif. It was an
    experiment, written before I stumbled into Tcl/Tk and discovered
    its immense productivity in GUI building. XEnv never got too far
    because it was really very-very slow to program in Motif\dots
\end{itemize}


\section{Repeating or iterating simulation runs}

Once your model works reliably, you'll usually want to run several
simulations. You may want to run the model with various
parameter settings, or you may want \textit{(should want?)} to
run the same model with the same parameter settings but with
different random number generator seeds, to achieve statistically
more reliable results.

Running a simulation several times by hand can easily become tedious,
and then a good solution is to write a control script that
takes care of the task automatically. Unix shell is
a natural language choice to write the control script in,
but other languages like Perl, Matlab/Octave, Tcl, Ruby might also have
justification for this purpose.

The next sections are only for Unix users. We'll use the
Unix `Bourne' shell (\ttt{sh}, \ttt{bash}) to write the control script.
If you'd prefer Matlab/Octave, the \ttt{contrib/octave/} directory
contains example scripts (contributed by Richard Lyon).


\subsection{Executing several runs}

In simple cases, you may define all simulation runs needed in the
\ttt{[Run 1]}, \ttt{[Run 2]}, etc. sections of \ttt{omnetpp.ini},
and invoke your simulation with the -r flag each time.
The -f flag lets you use a file name different from \ttt{omnetpp.ini}.

The following script executes a simulation named \ttt{wireless}
several times, with parameters for the different runs
given in the \ttt{runs.ini} file.

\begin{verbatim}
#! /bin/sh
./wireless -f runs.ini -r 1
./wireless -f runs.ini -r 2
./wireless -f runs.ini -r 3
./wireless -f runs.ini -r 4
...
./wireless -f runs.ini -r 10
\end{verbatim}

To run the above script, type it in a text file called e.g. \ttt{run},
give it \ttt{x} (executable) permission using \ttt{chmod},
then you can execute it by typing \ttt{./run}:

\begin{verbatim}
% chmod +x run
% ./run
\end{verbatim}

You can simplify the above script by using a \textit{for} loop.
In the example below, the variable \ttt{i} iterates through
the values of list given after the \ttt{in} keyword.
It is very practical, since you can leave out or add runs,
or change the order of runs by simply editing the list --
to demonstrate this, we skip run 6, and include run 15 instead.

\begin{verbatim}
#! /bin/sh
for i in 3 2 1 4 5 7 15 8 9 10; do
   ./wireless -f runs.ini -r $i
done
\end{verbatim}

If you have many runs, you can use a C-style loop:

\begin{verbatim}
#! /bin/sh
for ((i=1; $i<50; i++)); do
   ./wireless -f runs.ini -r $i
done
\end{verbatim}


\subsection{Variations over parameter values}

It may not be practical to hand-write descriptions of all runs
in an ini file, especially if there are many parameter
settings to try, or you want to try all possible
combinations of two or more parameters.
The solution might be to generate only a small fraction
of the ini file with the variable parameters, and
use it via ini file inclusion. For example, you might
write your \ttt{omnetpp.ini} like this:

\begin{verbatim}
[General]
network = Wireless

[Parameters]
Wireless.n = 10
...   # other fixed parameters
include params.ini  # include variable part
\end{verbatim}

And have the following as control script. It uses two nested loops to explore
all possible combinations of the \textit{alpha} and \textit{beta} parameters.
Note that \ttt{params.ini} is created by redirecting the \ttt{echo}
output into file, using the \ttt{>} and \ttt{>>} operators.

\begin{verbatim}
#! /bin/sh
for alpha in 1 2 5 10 20 50; do
   for beta in 0.1 0.2 0.3 0.4 0.5; do
       echo "Wireless.alpha=$alpha" > params.ini
       echo "Wireless.beta=$beta" >> params.ini
       ./wireless
   done
done
\end{verbatim}


As a heavy-weight example, here's the ``runall'' script of
Joel Sherrill's \textit{File System Simulator}. It also demonstrates
that loops can iterate over string values too, not just numbers.
(\texttt{omnetpp.ini} includes the generated \texttt{algorithms.ini}.)

Note that instead of redirecting every \ttt{echo} command to file,
they are grouped using parentheses, and redirected together.
The net effect is the same, but you can spare some typing this way.

\begin{verbatim}
#! /bin/bash
#
# This script runs multiple variations of the file system simulator.
#
all_cache_managers="NoCache FIFOCache LRUCache PriorityLRUCache..."
all_schedulers="FIFOScheduler SSTFScheduler CScanScheduler..."

for c in ${all_cache_managers}; do
  for s in ${all_schedulers}; do
  (
    echo "[Parameters]"
    echo "filesystem.generator_type = \"GenerateFromFile\""
    echo "filesystem.iolibrary_type = \"PassThroughIOLibrary\""
    echo "filesystem.syscalliface_type = \"PassThroughSysCallIface\""
    echo "filesystem.filesystem_type = \"PassThroughFileSystem\""
    echo "filesystem.cache_type = \"${c}\""
    echo "filesystem.blocktranslator_type = \"NoTranslation\""
    echo "filesystem.diskscheduler_type = \"${s}\""
    echo "filesystem.accessmanager_type = \"MutexAccessManager\""
    echo "filesystem.physicaldisk_type = \"HP97560Disk\""
  ) >algorithms.ini

  ./filesystem
  done
done
\end{verbatim}



\subsection{Variations over seed value (multiple independent runs)}

The same kind of control script can be used if you want to execute
several runs with different random seeds\index{random!seeds}.
The following code does 500 runs with independent seeds.
(\texttt{omnetpp.ini} should include \ttt{parameters.ini}.)

The seeds are 10 million numbers apart in the sequence (\ttt{seedtool}
parameter), so one run should not use more random numbers than this,
otherwise there will be overlaps in the sequences and the runs
will not be independent.

\begin{verbatim}
#! /bin/sh
seedtool g 1 10000000 500 > seeds.txt
for seed in `cat seeds.txt`; do
   (
     echo "[General]"
     echo "random-seed = ${seed}"
     echo "output-vector-file = xcube-${seed}.vec"
   ) > parameters.ini
   ./xcube
done
\end{verbatim}





\section{Akaroa support: Multiple Replications in Parallel}
\label{sec:ch-run-sim:akaroa}
\index{Akaroa}
\index{Multiple Replications in Parallel}

\subsection{Introduction}

Typical simulations are Monte-Carlo simulations: they use
(pseudo-)random numbers to drive the simulation model.
For the simulation to produce statistically reliable results,
one has to carefully consider the following:

\begin{itemize}
  \item{When is the initial transient over, when can we start
    collecting data? We usually do not want to include the
    initial transient when the simulation is still ``warming up.''}
  \item{When can we stop the simulation? We want to wait long enough
    so that the statistics we are collecting can ``stabilize'',
    can reach the required sample size to be statistically trustable.}
\end{itemize}

Neither questions are trivial to answer. One might just suggest
to wait ``very long'' or ``long enough''. However, this is neither
simple (how do you know what is ``long enough''?) nor practical
(even with today's high speed processors simulations of modest complexity
can take hours, and one may not afford multiplying runtimes by,
say, 10, ``just to be safe.'') If you need further convincing,
please read \cite{Pawlikowsky02} and be horrified.

A possible solution is to look at the statistics while the simulation
is running, and decide at runtime when enough data have been
collected for the results to have reached the required accuracy.
One possible criterion is given by the confidence level,
more precisely, by its width relative to the mean.
But ex ante it is unknown how many observations have to be collected
to achieve this level -- it must be determined runtime.


\subsection{What is Akaroa}

Akaroa \cite{Akaroa99} addresses the above problem.
According to its authors, Akaroa (Akaroa2) is a ``fully automated
simulation tool designed for running distributed stochastic simulations
in MRIP scenario'' in a cluster computing environment.

MRIP stands for \textit{Multiple Replications in Parallel}.
In MRIP, the computers of the cluster run independent replications
of the whole simulation process (i.e. with the same parameters but
different seed for the RNGs (random number generators)),
generating statistically equivalent streams of simulation output data.
These data streams are fed to a global data analyser responsible for
analysis of the final results and for stopping the simulation
when the results reach a satisfactory accuracy.

The independent simulation processes run independently of one another
and continuously send their observations to the central analyser
and control process. This process \textit{combines} the independent data streams,
and calculates from these observations an overall estimate of the mean value
of each parameter.
Akaroa2 decides by a given confidence level and precision
whether it has enough observations or not. When it judges that is
has enough observations it halts the simulation.

If \textit{n} processors are used, the needed simulation execution time
is usually \textit{n} times smaller compared to a one-processor
simulation (the required number of observations are produced sooner).
Thus, the simulation would be sped up approximately in proportion
to the number of processors used and sometimes even more.

Akaroa was designed at the University of Canterbury in Christchurch, New Zealand
and can be used free of charge for teaching and non-profit research activities.


\subsection{Using Akaroa with {\opp}}

\subsubsection{Akaroa}

Before the simulation can be run in parallel under Akaroa, you have to
start up the system:

\begin{itemize}
  \item{Start \ttt{akmaster} running in the background on some host.}
  \item{On each host where you want to run a simulation engine,
     start \ttt{akslave} in the background.}
\end{itemize}

Each \ttt{akslave} establishes a connection with the \ttt{akmaster}.

Then you use \ttt{akrun} to start a simulation. \ttt{akrun} waits
for the simulation to complete, and writes a report of the results
to the standard output. The basic usage of the \ttt{akrun} command is:

\begin{verbatim}
akrun -n num_hosts command [argument..]
\end{verbatim}

where \textit{command} is the name of the simulation you want to start.
Parameters for Akaroa are read from the file named \ttt{Akaroa} in
the working directory. Collected data from the processes are
sent to the \ttt{akmaster} process, and when the required precision
has been reached, \ttt{akmaster} tells the simulation processes to
terminate. The results are written to the standard output.

The above description is not detailed enough help you
set up and successfully use Akaroa -- for that you need to read the
Akaroa manual.

\subsubsection{Configuring {\opp} for Akaroa}

First of all, you have to compile {\opp} with Akaroa support enabled.

The {\opp} simulation must be configured in \ttt{omnetpp.ini}
so that it passes the observations to Akaroa. The simulation model itself does
not need to be changed -- it continues to write
the observations into output vectors (\cclass{cOutVector} objects,
see chapter \ref{cha:the-simulation-library}). You can place some of
the output vectors under Akaroa control.

You need to add the following to \ttt{omnetpp.ini}:

\begin{verbatim}
[General]
rng-class="cAkaroaRNG"
outputvectormanager-class="cAkOutputVectorManager"
\end{verbatim}

These lines cause the simulation to obtain random numbers from Akaroa,
and allows data written to selected output vectors to be passed to Akaroa's
global data analyser.
    \footnote{For more details on the plugin mechanism these settings make use of,
    see section \ref{sec:ch-opp-design:customization}.}

Akaroa's RNG is a Combined Multiple Recursive pseudorandom
number generator (CMRG) with a period of approximately $2^{191}$
random numbers, and provides a unique stream of random numbers
for every simulation engine. It is vital to obtain random numbers
from Akaroa: otherwise, all simulation processes would run with the same
RNG seeds, and produce exactly the same results!

Then you need to specify which output vectors you want to
be under Akaroa control. By default, all output vectors are under Akaroa
control; the

\begin{verbatim}
<modulename>.<vectorname>.akaroa=false
\end{verbatim}

setting can be used to make Akaroa ignore specific vectors.
You can use the \ttt{*}, \ttt{**} wildcards here (see
section \ref{sec:ch-run-sim:wildcards}). For example,
if you only want a few vectors be placed under Akaroa,
you can use the following trick:

\begin{verbatim}
<modulename>.<vectorname1>.akaroa=true
<modulename>.<vectorname2>.akaroa=true
...
**.*.akaroa=false  # catches everything not matched above
\end{verbatim}


\subsubsection{Using shared file systems}
\label{sec:run-sim:using-shared-filesystems}

It is usually practical to have the same physical disk mounted (e.g. via NFS or Samba)
on all computers in the cluster. However, because all {\opp} simulation
processes run with the same settings, they would overwrite each other's
output files (e.g. \ttt{omnetpp.vec}, \ttt{omnetpp.sca}).
Your can prevent this from happening using the
\ttt{fname-append-host} ini file entry:

\begin{verbatim}
[General]
fname-append-host=yes
\end{verbatim}

When turned on, it appends the host name to the names of the output
files (output vector, output scalar, snapshot files).



\section{Typical issues}

\subsection{Stack problems}

\subsubsection{``Stack violation (\textit{FooModule} stack too small?) in module \textit{bar.foo}''}
\index{stack!too small}

{\opp} detected that the module has used more stack space than it has
allocated. The solution is to increase the stack for that module type.
You can call the \fname{getStackUsage()} from \fname{finish()} to find out
actually how much stack the module used.


\subsubsection{``Error: Cannot allocate \textit{nn} bytes stack for module \textit{foo.bar''}}

The resolution depends on whether you are using {\opp} on Unix or on Windows.

\textbf{Unix.}
If you get the above message, you have to increase the total stack
size\index{stack!size} (the sum of all coroutine stacks). You can do
so in \texttt{omnetpp.ini}:

\begin{verbatim}
[General]
total-stack-kb = 2048 # 2MB
\end{verbatim}

There is no penalty if you set \fpar{total-stack-kb} too high. I
recommend to set it to a few K less than the maximum process stack
size allowed by the operating system (\fprog[ulimit]{ulimit -s}; see
next section).


\textbf{Windows.}
You need to set a \textit{low} (!) ``reserved stack size''
in the linker options, for example 64K (/stack:65536 linker flag) will do.
The ``reserved stack size'' is an attribute in the Windows exe
files' internal header. It can be set from the linker, or with
the \ttt{editbin} Microsoft utility. You can use the \ttt{opp\_stacktool}
program (which relies on another Microsoft utility called \ttt{dumpbin})
to display reserved stack size for executables.

You need a low reserved stack size because the Win32 Fiber API
which is the mechanism underlying \fname{activity()} uses
this number as coroutine stack size, and with 1MB being the default,
it is easy to run out of the 2GB possible address space (2GB/1MB=2048).

A more detailed explanation follows.
Each fiber has its own stack, by default 1MB (this is the ``reserved''
stack space -- i.e. reserved in the address space, but not the full
1MB is actually ``committed'', i.e. has physical memory assigned to it).
This means that a 2GB address space will run out after 2048 fibers,
which is way too few. (In practice, you won't even be able to create
this many fibers, because physical memory is also a limiting factor).
Therefore, the 1MB reserved stack size (RSS) must be set to a smaller
value: the coroutine stack size requested for the module, plus
the \ttt{extra-stack-kb} amount for Cmdenv/Tkenv -- which makes
about 16K with Cmdenv, and about 48K when using Tkenv.
Unfortunately, the CreateFiber() Win32 API doesn't allow the RSS to be
specified. The more advanced CreateFiberEx() API which accepts RSS as
parameter is unfortunately only available from Windows XP.

The alternative is the stacksize parameter stored in the EXE header,
which can be set
via the STACKSIZE .def file parameter, via the /stack linker option,
or on an existing executable using the editbin /stack utility.
This parameter specifies a common RSS for the main program stack,
fiber and thread stacks. 64K should be enough. This is the way
simulation executable should be created: linked with the /stack:65536
option, or the /stack:65536 parameter applied using editbin later.
For example, after applying the editbin /stacksize:65536 command to
dyna.exe, I was able to successfully run the Dyna sample with 8000
Client modules on my Win2K PC with 256M RAM (that means about 12000
modules at runtime, including about 4000 dynamically created modules.)


\subsubsection{``Segmentation fault''}

On Unix, if you set the total stack size higher, you may get a
segmentation fault during network setup\index{segmentation fault} (or
during execution if you use dynamically created modules) for exceeding
the operating system limit for maximum stack size. For example, in
Linux 2.4.x, the default stack limit is 8192K (that is, 8MB). The
\fprog{ulimit} shell command can be used to modify the
resource limits, and you can raise the allowed maximum stack size
up to 64M.

\begin{verbatim}
$ ulimit -s 65500
$ ulimit -s
65500
\end{verbatim}

Further increase is only possible if you're root.
Resource limits are inherited by child processes.
The following sequence can be used under Linux to get a shell with
256M stack limit:

\begin{verbatim}
$ su root
Password:
# ulimit -s 262144
# su andras
$ ulimit -s
262144
\end{verbatim}

If you do not want to go through the above process at each login, you
can change the limit in the PAM configuration files. In Redhat Linux
(maybe other systems too), add the following line to
\ttt{/etc/pam.d/login}:

\begin{verbatim}
session    required    /lib/security/pam_limits.so
\end{verbatim}

and the following line to \ttt{/etc/security/limits.conf}:

\begin{verbatim}
*    hard    stack    65536
\end{verbatim}

\begin{sloppypar}
A more drastic solution is to recompile the kernel with a larger stack
limit. Edit \ttt{/usr/src/linux/include/linux/sched.h} and increase
\ttt{\_STK\_LIM} from \ttt{(8*1024*1024)} to \ttt{(64*1024*1024)}.
\end{sloppypar}

Finally, it you're tight with memory, you can switch to Cmdenv. Tkenv
increases the stack size of each module by about 32K\index{stack!for
  Tkenv} so that user interface code that is called from a
simple module's context can be safely executed.
Cmdenv does not need that much extra stack.


\subsubsection{Eventually...}

Once you get to the point where you have to adjust the total stack size
to get your program running,
you should probably consider transforming (some of) your \fname{activity()}
simple modules to \fname{handleMessage()}. \fname{activity()} does not
scale well for large simulations.



\subsection{Memory leaks and crashes}

The most common problems in C++ are associated with memory allocation
(usage of \ttt{new} and \ttt{delete}):

\begin{itemize}
   \item{\textit{memory leaks,} that is, forgetting to delete objects
     or memory blocks no longer used;}
   \item{\textit{crashes,} usually due to referring to an already deleted
     object or memory block, or trying to delete one for a second time;}
   \item{\textit{heap corruption} (enventually leading to crash) due to
     overrunning allocated blocks, i.e. writing past the end of an allocated
     array.}
\end{itemize}

By far the most common ways leaking memory in simulation programs
is by not deleting messages (\cclass{cMessage} objects or subclasses).
Both Tkenv and Cmdenv are able to display the number of messages
currently in the simulation,
see e.g. section \ref{sec:ch-run-sim:interpreting-cmdenv-output}.
If you find that the number of messages is steadily increasing,
you need to find where the message objects are. You can do so
by selecting \textit{Inspect|From list of all objects...} from
the Tkenv menu, and reviewing the list in the dialog that pops up.
(If the model is large, it may take a while for the dialog to appear.)

If the number of messages is stable, it is still possible
you're leaking other \cclass{cOwnedObject}-based objects. You can
also find them using Tkenv's \textit{Inspect|From list of all objects...}
function.

If you're leaking non-\cclass{cOwnedObject}-based objects or just
memory blocks (\ttt{struct}s, \ttt{int}/\ttt{double}/\ttt{struct} arrays,
etc, allocated by \ttt{new}), you cannot find them via Tkenv.
You'll probably need a specialized memory debugging tool like
the ones described below.

\subsubsection{Memory debugging tools}

If you suspect that you may have memory allocation problems
(crashes associated with double-deletion or accessing already
deleted block, or memory leaks), you can use specialized tools
to track them down.

By far the most efficient, most robust and most versatile tool
is \textit{Valgrind}, originally developed for debugging KDE.

Other memory debuggers are \textit{NJAMD}, \textit{MemProf},
\textit{MPatrol}, \textit{dmalloc} and \textit{ElectricFence}.
Most of the above tools support tracking down memory leaks as well as
detecting double deletion, writing past the end of an allocated block, etc.

A proven commercial tool \textit{Rational Purify}. It has
a good reputation and proved its usefulness many times.


\subsection{Simulation executes slowly}

What can you do if the simulation executes much slower than you expect?
The best advice that can be given here is that you should
\tbf{use a good profiler} to find out how much time is spent in each
part of the program. Do not make the mistake of omitting this step,
thinking that you know "which part is slow"! Even for experienced
programmers, profiling session is all too often full of surprises.
It often turns out that lots of CPU time is spent in completely
innocent-looking statements, while the big and complex algorithm
doesn't take nearly as much time as expected. \textit{Don't assume anything
-- profile before you optimize!}
    \footnote{And before blaming the simulation kernel for poor performance...}

A really impressive profiler on Linux is the \textit{Valgrind}-based
\textit{callgrind}, and its visualizer \textit{KCachegrind}.
Unfortunately it won't be ported to Windows anytime soon.
On Windows, you're out of luck -- commercial products may help, or,
port your simulation to Linux. The latter goes usually much smoother
than one would expect.


%
%Use a profiler! KCachegrind.
%
%EV trick.
%
%Here are a few tips that can help you make the simulation faster:
%\begin{itemize}
%  \item{Use message subclassing instead of adding \fname{cPar}'s to messages.}
%  \item{Try to minimize message creations and deletions. Reuse
%    messages if possible.}
%  \item{Turn off the display of screen messages when you run the
%    simulation.  You can do this in the ini file. Alternatively, you
%    can place \ttt{\#ifdef}s around your \texttt{ev<<} and
%    \index{ev.printf()} calls and turn off the define when compiling
%    the simulation for speed.}
%  \item{Store the module parameters in local variables to avoid
%    calling \cclass{cPar} member functions every time.}
%\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "usman"
%%% End:

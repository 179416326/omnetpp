\chapter{Running Simulations}
\label{cha:run-sim}

\section{User interfaces}

{\opp} simulations can be run under different user interfaces.
Currently the following user interfaces are supported:

\begin{itemize}
  \item Tkenv: Tcl/Tk-based graphical, windowing user interface
  \item Cmdenv: command-line user interface for batch execution
\end{itemize}


You would typically test and debug your simulation under Tkenv,
then run actual simulation experiments from the command line or
shell script, using Cmdenv. Tkenv is also better suited for educational or
demonstration purposes.

Both Tkenv and Cmdenv are provided in the form of a library, and
you choose between them by linking one or the other into your
simulation executable. (Creating the executable was described in
chapter \ref{cha:building-simulation-programs}). Both user interfaces
are supported on Unix and Windows platforms.

Common functionality in Tkenv and Cmdenv has been collected and
placed into the Envir library\index{Envir}, which can be thought of as the
``common base class'' for the two user interfaces.

The user interface\index{user interface} is separated from the
simulation kernel, and the two parts interact through a well-defined
interface. This also means that, if needed, you can write your
own user interface or embed an {\opp} simulation into your application
without any change to models or the simulation library.

\section{Cmdenv: the command-line interface}

The command line user interface\index{command line user interface} is
a small, portable and fast user interface that compiles and runs on
all platforms. Cmdenv\index{Cmdenv} is designed primarily for batch execution.

Cmdenv uses simply executes some or all simulation runs that are described
in the configuration file. If one run stops with an error message,
subsequent ones will still be executed. The runs to be executed can be
passed via command-line argument or in the ini file.

\subsection{Command-line switches}

A simulation program built with Cmdenv accepts the following command line
switches\index{command line switches}:

\begin{longtable}{lp{12cm}}
  \ttt{-h}
  &
  The program prints a short help message and the networks
  contained in the executable, then exits.\\

  \ttt{-f} \texttt{<}\textit{fileName\texttt{>}}
  &
  Specify the name of the configuration file.
  The default is \texttt{omnetpp.ini}\index{omnetpp.ini}.
  Multiple \ttt{-f} switches can be given; this allows you to partition your
  configuration file.  For example, one file can contain your general
  settings, another one most of the module parameters, another one the
  module parameters you change often.\\

  \ttt{-l} \texttt{<}\textit{fileName\texttt{>}}
  &
  Load a shared object\index{shared objects} (\texttt{.so} file on Unix).
  Multiple \ttt{-l} switches are accepted. Your \texttt{.so} files may contain module
  code etc. By dynamically loading all simple
  module code and compiled network description (\texttt{\_n.o} files
  on Unix) you can even eliminate the need to re-link the simulation
  program after each change in a source file.  (Shared objects can be
  created with \texttt{gcc -shared...})\\

  \ttt{-r} \texttt{<}\textit{runs\texttt{>}}
  &
  It specifies which runs should be executed (e.g. \ttt{-r 2,4,6-8}).
  This option overrides the \texttt{runs-to-execute=} option
  in the \texttt{[Cmdenv]} section of the ini file\index{ini file}
  (see later).\\
\end{longtable}

All other options are read from the configuration file.

An example of running an {\opp} executable with the -h flag:

\begin{verbatim}
$ ./fddi -h

{\opp} Discrete Event Simulation  (C) 1992-2005 Andras Varga
See the license for distribution terms and warranty disclaimer
Setting up Tkenv...

Command line options:
  -h            Print this help and exit.
  -f <inifile>  Use the given ini file instead of omnetpp.ini. Multiple
                -f options are accepted to load several ini files.
  -u <ui>       Selects the user interface. Standard choices are Cmdenv
                and Tkenv. To make a user interface available, you need
                to link the simulation executable with the cmdenv/tkenv
                library, or load it as shared library via the -l option.
  -l <library>  Load the specified shared library (.so or .dll) on startup.
                The file name should be given without the .so or .dll suffix
                (it will be appended automatically.) The loaded module may
                contain simple modules, plugins, etc. Multiple -l options
                can be present.

Tkenv-specific options:
  -r <run>      Set up the given run, specified in a [Run n] section of
                the ini file.

The following components are available:
  module types:
    FDDI_Monitor
    FDDI_Generator4Sniffer
    FDDI_Generator4Ring
    ...

End run of {\opp}
\end{verbatim}


\subsection{Cmdenv ini file options}
\label{sec:ch-run-sim:cmdenv-section}

Cmdenv can be executed in two modes, selected by the \ttt{express-mode} ini file entry:

\begin{itemize}
    \item \tbf{Normal} (non-express) mode is for debugging: detailed information
        will be written to the standard output (event banners, module output,
        etc).
    \item \tbf{Express} mode can be used for long simulation runs: only
        periodical status update is displayed about the progress of the
        simulation.
\end{itemize}

The full list of ini file options recognized by Cmdenv:

\begin{longtable}{|p{6.5cm}|p{7.5cm}|}
\hline
\tabheadcol
\tbf{Entry and default value} & \tbf{Description}\\\hline
\multicolumn{2}{|l|}{\tbf{[Cmdenv]}}\\\hline
%%
\fpar{runs-to-execute} = & Specifies which simulation runs should be executed.
It accepts a comma-separated list of run numbers or run number ranges, e.g.
\ttt{1,3-4,7-9}. If the value is missing, Cmdenv executes all runs that have
ini file sections; if no runs are specified in the ini file, Cmdenv does one run.
The -r command line option overrides this ini file setting. \\\hline
%%
\fpar{express-mode}=yes/no (default: no) & Selects ``normal'' (debug/trace) or ``express'' mode.
\\\hline
%%
\fpar{module-messages}=yes/no (default: yes) & In normal mode only:
printing module ev<< output on/off \\\hline
%%
\fpar{event-banners}=yes/no (default: yes) & In normal mode only:
printing event banners on/off \\\hline
%%
\fpar{message-trace}=yes/no (default: no) & In normal mode only: print a line
about each message sending (by \fname{send()},\fname{scheduleAt()}, etc)
and delivery on the standard output \\\hline
%%
\fpar{autoflush}=yes/no (default: no) &  Call \fname{fflush(stdout)} after each
event banner or status update; affects both express and normal mode. Turning on
autoflush can be useful with printf-style debugging for tracking down
program crashes. \\\hline
%%
\fpar{status-frequency}=<integer> (default: 50000) & In express mode only:
print status update every n events (on today's computers, and
for a typical model, this will produce an update every few seconds,
perhaps a few times per second) \\\hline
%%
\fpar{performance-display}=yes/no (default: yes) & In express mode only:
print detailed performance information. Turning it on results in a 3-line
entry printed on each update, containing ev/sec, simsec/sec, ev/simsec,
number of messages created/still present/currently scheduled in FES\index{FES}.
\\\hline
%%
\fpar{extra-stack-kb} = 8 & Specifies the extra amount of stack
(in kilobytes) that is reserved for each \fname{activity()}
simple module when the simulation is run under Cmdenv.\\\hline
\end{longtable}


\subsection{Interpreting Cmdenv output}
\label{sec:ch-run-sim:interpreting-cmdenv-output}

When the simulation is running in ``express'' mode with detailed
performance display enabled, Cmdenv periodically outputs a three-line
status info about the progress of the simulation.
The output looks like this:

\begin{verbatim}
...
** Event #250000   T=123.74354 ( 2m  3s)    Elapsed: 0m 12s
     Speed:     ev/sec=19731.6   simsec/sec=9.80713   ev/simsec=2011.97
     Messages:  created: 55532   present: 6553   in FES: 8
** Event #300000   T=148.55496 ( 2m 28s)    Elapsed: 0m 15s
     Speed:     ev/sec=19584.8   simsec/sec=9.64698   ev/simsec=2030.15
     Messages:  created: 66605   present: 7815   in FES: 7
...
\end{verbatim}

The first line of the status display (beginning with \ttt{**})
contains:

\begin{itemize}
   \item{how many events have been processed so far}
   \item{the current simulation time (T), and}
   \item{the elapsed time (wall clock time) since the beginning of the simulation run.}
\end{itemize}

The second line displays info about simulation performance:

\begin{itemize}
   \item{\ttt{ev/sec} indicates \textit{performance}: how many events are processed
     in one real-time second.  On one hand it depends on your hardware
     (faster CPUs process more events per second), and on the other hand
     it depends on the complexity (amount of calculations) associated
     with processing one event. For example, protocol simulations tend to require
     more processing per event than e.g. queueing networks, thus
     the latter produce higher ev/sec values.
     In any case, this value is independent of the size (number of modules) in your model.}
   \item{\ttt{simsec/sec} shows \textit{relative speed} of the simulation, that is,
     how fast the simulation is progressing compared to real time, how many
     simulated seconds can be done in one real second. This value virtuall depends
     on everything: on the hardware, on the size of the simulation model,
     on the complexity of events, and the average simulation time between events as well.}
   \item{\ttt{ev/simsec} is the \textit{event density}: how many events are
     there per simulated second. Event density only depends on the simulation model,
     regardless of the hardware used to simulate it: in a cell-level ATM simulation
     you'll have very hight values ($10^9$), while in a bank teller simulation
     this value is probably well under 1. It also depends on the size of your
     model: if you double the number of modules in your model, you can expect
     the event density double, too.}
\end{itemize}

The third line displays the number of messages, and it is important
because it may indicate the `health' of your simulation.

\begin{itemize}
   \item{\ttt{Created}: total number of message objects created since the
     beginning of the simulation run. This does not mean that this many message
     object actually exist, because some (many) of them may have been deleted
     since then. It also does not mean that \textit{you} created all those
     messages -- the simulation kernel also creates messages for its own use
     (e.g. to implement \ttt{wait()} in an \ttt{activity()} simple module).}
   \item{\ttt{Present}: the number of message objects currently present
     in the simulation model, that is, the number of messages created (see above)
     minus the number of messages already deleted. This number includes
     the messages in the FES\index{FES}.}
   \item{\ttt{In FES}: the number of messages currently scheduled in the
     Future Event Set.}
\end{itemize}


The second value, the number of messages present is more useful than
perhaps one would initially think. It can indicator of the `health' of the simulation:
if it is growing steadily, then either you have a memory leak and losing
messages (which indicates a programming error), or the network you simulate is
overloaded and queues are steadily filling up (which might indicate wrong input
parameters).

Of course, if the number of messages does not increase, it does not mean
that you do \textit{not} have a memory leak (other memory leaks are also
possible). Nevertheless the value is still useful, because by far the
most common way of leaking memory in a simulation is by not deleting messages.



\section{Tkenv: the graphical user interface}

\subsubsection{Features}

Tkenv\index{Tkenv} is a portable graphical windowing user interface.
Tkenv supports interactive execution of the simulation, tracing and
debugging\index{simulation!debugging}. Tkenv is recommended in the
development stage of a simulation or for presentation and educational
purposes, since it allows one to get a detailed picture of the state
of simulation at any point of execution and to follow what happens
inside the network.

\subsection{Command-line switches}

A simulation program built with Tkenv accepts the following command line
switches\index{command line switches}:

\begin{longtable}{lp{12cm}}
  \ttt{-h}
  &
  The program prints a short help message and the networks
  contained in the executable, then exits.\\

  \ttt{-f }\textit{<fileName>}
  &
  Specify the name of the configuration file.
  The default is \texttt{omnetpp.ini}\index{omnetpp.ini}.
  Multiple \ttt{-f} switches can be given; this allows you to partition your
  configuration file.  For example, one file can contain your general
  settings, another one most of the module parameters, another one the
  module parameters you change often.\\

  \ttt{-l }\textit{<fileName>}
  &
  Load a shared object\index{shared objects} (\texttt{.so} file on Unix).
  Multiple \ttt{-l} switches are accepted. Your \texttt{.so} files may contain module
  code etc. By dynamically loading all simple
  module code and compiled network description (\texttt{\_n.o} files
  on Unix) you can even eliminate the need to re-link the simulation
  program after each change in a source file.  (Shared objects can be
  created with \texttt{gcc -shared...})\\

  \ttt{-r }\textit{<run-number>}
  &
  It has the same effect as (but takes priority over) the \ttt{[Tkenv]/default-run=}
  ini file entry.

\end{longtable}

\subsection{In Memoriam\dots }

There used to be other windowing user interfaces which have been removed
from the distribution:

\begin{itemize}
  \item \tbf{TVEnv}. A Turbo Vision-based user interface, the first
    interactive UI for {\opp}. Turbo Vision was an excellent
    character-graphical windowing environment, originally shipped with
    Borland C++ 3.1.
  \item \tbf{XEnv}. A GUI written in pure X/Motif. It was an
    experiment, written before I stumbled into Tcl/Tk and discovered
    its immense productivity in GUI building. XEnv never got too far
    because it was really very-very slow to program in Motif\dots
\end{itemize}


\section{Repeating or iterating simulation runs}

Once your model works reliably, you'll usually want to run several
simulations. You may want to run the model with various
parameter settings, or you may want \textit{(should want?)} to
run the same model with the same parameter settings but with
different random number generator seeds, to achieve statistically
more reliable results.

Running a simulation several times by hand can easily become tedious,
and then a good solution is to write a control script that
takes care of the task automatically. Unix shell is
a natural language choice to write the control script in,
but other languages like Perl, Matlab/Octave, Tcl, Ruby might also have
justification for this purpose.

The next sections are only for Unix users. We'll use the
Unix `Bourne' shell (\ttt{sh}, \ttt{bash}) to write the control script.
If you'd prefer Matlab/Octave, the \ttt{contrib/octave/} directory
contains example scripts (contributed by Richard Lyon).


\subsection{Executing several runs}

In simple cases, you may define all simulation runs needed in the
\ttt{[Run 1]}, \ttt{[Run 2]}, etc. sections of \ttt{omnetpp.ini},
and invoke your simulation with the -r flag each time.
The -f flag lets you use a file name different from \ttt{omnetpp.ini}.

The following script executes a simulation named \ttt{wireless}
several times, with parameters for the different runs
given in the \ttt{runs.ini} file.

\begin{verbatim}
#! /bin/sh
./wireless -f runs.ini -r 1
./wireless -f runs.ini -r 2
./wireless -f runs.ini -r 3
./wireless -f runs.ini -r 4
...
./wireless -f runs.ini -r 10
\end{verbatim}

To run the above script, type it in a text file called e.g. \ttt{run},
give it \ttt{x} (executable) permission using \ttt{chmod},
then you can execute it by typing \ttt{./run}:

\begin{verbatim}
$ chmod +x run
$ ./run
\end{verbatim}

You can simplify the above script by using a \textit{for} loop.
In the example below, the variable \ttt{i} iterates through
the values of list given after the \ttt{in} keyword.
It is very practical, since you can leave out or add runs,
or change the order of runs by simply editing the list --
to demonstrate this, we skip run 6, and include run 15 instead.

\begin{verbatim}
#! /bin/sh
for i in 3 2 1 4 5 7 15 8 9 10; do
   ./wireless -f runs.ini -r $i
done
\end{verbatim}

If you have many runs, you can use a C-style loop:

\begin{verbatim}
#! /bin/sh
for ((i=1; $i<50; i++)); do
   ./wireless -f runs.ini -r $i
done
\end{verbatim}


\subsection{Variations over parameter values}

It may not be practical to hand-write descriptions of all runs
in an ini file, especially if there are many parameter
settings to try, or you want to try all possible
combinations of two or more parameters.
The solution might be to generate only a small fraction
of the ini file with the variable parameters, and
use it via ini file inclusion. For example, you might
write your \ttt{omnetpp.ini} like this:

\begin{verbatim}
[General]
network = Wireless

[Parameters]
Wireless.n = 10
...   # other fixed parameters
include params.ini  # include variable part
\end{verbatim}

And have the following as control script. It uses two nested loops to explore
all possible combinations of the \textit{alpha} and \textit{beta} parameters.
Note that \ttt{params.ini} is created by redirecting the \ttt{echo}
output into file, using the \ttt{>} and \ttt{>>} operators.

\begin{verbatim}
#! /bin/sh
for alpha in 1 2 5 10 20 50; do
   for beta in 0.1 0.2 0.3 0.4 0.5; do
       echo "Wireless.alpha=$alpha" > params.ini
       echo "Wireless.beta=$beta" >> params.ini
       ./wireless
   done
done
\end{verbatim}


As a heavy-weight example, here's the ``runall'' script of
Joel Sherrill's \textit{File System Simulator}. It also demonstrates
that loops can iterate over string values too, not just numbers.
(\texttt{omnetpp.ini} includes the generated \texttt{algorithms.ini}.)

Note that instead of redirecting every \ttt{echo} command to file,
they are grouped using parentheses, and redirected together.
The net effect is the same, but you can spare some typing this way.

\begin{verbatim}
#! /bin/bash
#
# This script runs multiple variations of the file system simulator.
#
all_cache_managers="NoCache FIFOCache LRUCache PriorityLRUCache..."
all_schedulers="FIFOScheduler SSTFScheduler CScanScheduler..."

for c in ${all_cache_managers}; do
  for s in ${all_schedulers}; do
  (
    echo "[Parameters]"
    echo "filesystem.generator_type = \"GenerateFromFile\""
    echo "filesystem.iolibrary_type = \"PassThroughIOLibrary\""
    echo "filesystem.syscalliface_type = \"PassThroughSysCallIface\""
    echo "filesystem.filesystem_type = \"PassThroughFileSystem\""
    echo "filesystem.cache_type = \"${c}\""
    echo "filesystem.blocktranslator_type = \"NoTranslation\""
    echo "filesystem.diskscheduler_type = \"${s}\""
    echo "filesystem.accessmanager_type = \"MutexAccessManager\""
    echo "filesystem.physicaldisk_type = \"HP97560Disk\""
  ) >algorithms.ini

  ./filesystem
  done
done
\end{verbatim}



\subsection{Variations over seed value (multiple independent runs)}

The same kind of control script can be used if you want to execute
several runs with different random seeds\index{random!seeds}.
The following code does 500 runs with independent seeds.
(\texttt{omnetpp.ini} should include \ttt{parameters.ini}.)

The seeds are 10 million numbers apart in the sequence (\ttt{seedtool}
parameter), so one run should not use more random numbers than this,
otherwise there will be overlaps in the sequences and the runs
will not be independent.

\begin{verbatim}
#! /bin/sh
seedtool g 1 10000000 500 > seeds.txt
for seed in `cat seeds.txt`; do
   (
     echo "[General]"
     echo "random-seed = ${seed}"
     echo "output-vector-file = xcube-${seed}.vec"
   ) > parameters.ini
   ./xcube
done
\end{verbatim}





\section{Akaroa support: Multiple Replications in Parallel}
\label{sec:ch-run-sim:akaroa}
\index{Akaroa}
\index{Multiple Replications in Parallel}

\subsection{Introduction}

Typical simulations are Monte-Carlo simulations: they use
(pseudo-)random numbers to drive the simulation model.
For the simulation to produce statistically reliable results,
one has to carefully consider the following:

\begin{itemize}
  \item{When is the initial transient over, when can we start
    collecting data? We usually do not want to include the
    initial transient when the simulation is still ``warming up.''}
  \item{When can we stop the simulation? We want to wait long enough
    so that the statistics we are collecting can ``stabilize'',
    can reach the required sample size to be statistically trustable.}
\end{itemize}

Neither questions are trivial to answer. One might just suggest
to wait ``very long'' or ``long enough''. However, this is neither
simple (how do you know what is ``long enough''?) nor practical
(even with today's high speed processors simulations of modest complexity
can take hours, and one may not afford multiplying runtimes by,
say, 10, ``just to be safe.'') If you need further convincing,
please read \cite{Pawlikowsky02} and be horrified.

A possible solution is to look at the statistics while the simulation
is running, and decide at runtime when enough data have been
collected for the results to have reached the required accuracy.
One possible criterion is given by the confidence level,
more precisely, by its width relative to the mean.
But ex ante it is unknown how many observations have to be collected
to achieve this level -- it must be determined runtime.


\subsection{What is Akaroa}

Akaroa \cite{Akaroa99} addresses the above problem.
According to its authors, Akaroa (Akaroa2) is a ``fully automated
simulation tool designed for running distributed stochastic simulations
in MRIP scenario'' in a cluster computing environment.

MRIP stands for \textit{Multiple Replications in Parallel}.
In MRIP, the computers of the cluster run independent replications
of the whole simulation process (i.e. with the same parameters but
different seed for the RNGs (random number generators)),
generating statistically equivalent streams of simulation output data.
These data streams are fed to a global data analyser responsible for
analysis of the final results and for stopping the simulation
when the results reach a satisfactory accuracy.

The independent simulation processes run independently of one another
and continuously send their observations to the central analyser
and control process. This process \textit{combines} the independent data streams,
and calculates from these observations an overall estimate of the mean value
of each parameter.
Akaroa2 decides by a given confidence level and precision
whether it has enough observations or not. When it judges that is
has enough observations it halts the simulation.

If \textit{n} processors are used, the needed simulation execution time
is usually \textit{n} times smaller compared to a one-processor
simulation (the required number of observations are produced sooner).
Thus, the simulation would be sped up approximately in proportion
to the number of processors used and sometimes even more.

Akaroa was designed at the University of Canterbury in Christchurch, New Zealand
and can be used free of charge for teaching and non-profit research activities.


\subsection{Using Akaroa with {\opp}}

\subsubsection{Akaroa}

Before the simulation can be run in parallel under Akaroa, you have to
start up the system:

\begin{itemize}
  \item{Start \ttt{akmaster} running in the background on some host.}
  \item{On each host where you want to run a simulation engine,
     start \ttt{akslave} in the background.}
\end{itemize}

Each \ttt{akslave} establishes a connection with the \ttt{akmaster}.

Then you use \ttt{akrun} to start a simulation. \ttt{akrun} waits
for the simulation to complete, and writes a report of the results
to the standard output. The basic usage of the \ttt{akrun} command is:

\begin{verbatim}
akrun -n num_hosts command [argument..]
\end{verbatim}

where \textit{command} is the name of the simulation you want to start.
Parameters for Akaroa are read from the file named \ttt{Akaroa} in
the working directory. Collected data from the processes are
sent to the \ttt{akmaster} process, and when the required precision
has been reached, \ttt{akmaster} tells the simulation processes to
terminate. The results are written to the standard output.

The above description is not detailed enough help you
set up and successfully use Akaroa -- for that you need to read the
Akaroa manual.

\subsubsection{Configuring {\opp} for Akaroa}

First of all, you have to compile {\opp} with Akaroa support enabled.

The {\opp} simulation must be configured in \ttt{omnetpp.ini}
so that it passes the observations to Akaroa. The simulation model itself does
not need to be changed -- it continues to write
the observations into output vectors (\cclass{cOutVector} objects,
see chapter \ref{cha:the-simulation-library}). You can place some of
the output vectors under Akaroa control.

You need to add the following to \ttt{omnetpp.ini}:

\begin{verbatim}
[General]
rng-class="cAkaroaRNG"
outputvectormanager-class="cAkOutputVectorManager"
\end{verbatim}

These lines cause the simulation to obtain random numbers from Akaroa,
and allows data written to selected output vectors to be passed to Akaroa's
global data analyser.
    \footnote{For more details on the plugin mechanism these settings make use of,
    see section \ref{sec:ch-plugin-exts:customization}.}

Akaroa's RNG is a Combined Multiple Recursive pseudorandom
number generator (CMRG) with a period of approximately $2^{191}$
random numbers, and provides a unique stream of random numbers
for every simulation engine. It is vital to obtain random numbers
from Akaroa: otherwise, all simulation processes would run with the same
RNG seeds, and produce exactly the same results!

Then you need to specify which output vectors you want to
be under Akaroa control. By default, all output vectors are under Akaroa
control; the

\begin{verbatim}
<modulename>.<vectorname>.akaroa=false
\end{verbatim}

setting can be used to make Akaroa ignore specific vectors.
You can use the \ttt{*}, \ttt{**} wildcards here (see
section \ref{sec:ch-run-sim:wildcards}). For example,
if you only want a few vectors be placed under Akaroa,
you can use the following trick:

\begin{verbatim}
<modulename>.<vectorname1>.akaroa=true
<modulename>.<vectorname2>.akaroa=true
...
**.*.akaroa=false  # catches everything not matched above
\end{verbatim}


\subsubsection{Using shared file systems}
\label{sec:run-sim:using-shared-filesystems}

It is usually practical to have the same physical disk mounted (e.g. via NFS or Samba)
on all computers in the cluster. However, because all {\opp} simulation
processes run with the same settings, they would overwrite each other's
output files (e.g. \ttt{omnetpp.vec}, \ttt{omnetpp.sca}).
Your can prevent this from happening using the
\ttt{fname-append-host} ini file entry:

\begin{verbatim}
[General]
fname-append-host=yes
\end{verbatim}

When turned on, it appends the host name to the names of the output
files (output vector, output scalar, snapshot files).



\section{Typical issues}

\subsection{Stack problems}

\subsubsection{``Stack violation (\textit{FooModule} stack too small?) in module \textit{bar.foo}''}
\index{stack!too small}

{\opp} detected that the module has used more stack space than it has
allocated. The solution is to increase the stack for that module type.
You can call the \fname{getStackUsage()} from \fname{finish()} to find out
actually how much stack the module used.


\subsubsection{``Error: Cannot allocate \textit{nn} bytes stack for module \textit{foo.bar''}}

The resolution depends on whether you are using {\opp} on Unix or on Windows.

\textbf{Unix.}
If you get the above message, you have to increase the total stack
size\index{stack!size} (the sum of all coroutine stacks). You can do
so in \texttt{omnetpp.ini}:

\begin{verbatim}
[General]
total-stack-kb = 2048 # 2MB
\end{verbatim}

There is no penalty if you set \fpar{total-stack-kb} too high. I
recommend to set it to a few K less than the maximum process stack
size allowed by the operating system (\fprog[ulimit]{ulimit -s}; see
next section).


\textbf{Windows.}
You need to set a \textit{low} (!) ``reserved stack size''
in the linker options, for example 64K (/stack:65536 linker flag) will do.
The ``reserved stack size'' is an attribute in the Windows exe
files' internal header. It can be set from the linker, or with
the \ttt{editbin} Microsoft utility. You can use the \ttt{opp\_stacktool}
program (which relies on another Microsoft utility called \ttt{dumpbin})
to display reserved stack size for executables.

You need a low reserved stack size because the Win32 Fiber API
which is the mechanism underlying \fname{activity()} uses
this number as coroutine stack size, and with 1MB being the default,
it is easy to run out of the 2GB possible address space (2GB/1MB=2048).

A more detailed explanation follows.
Each fiber has its own stack, by default 1MB (this is the ``reserved''
stack space -- i.e. reserved in the address space, but not the full
1MB is actually ``committed'', i.e. has physical memory assigned to it).
This means that a 2GB address space will run out after 2048 fibers,
which is way too few. (In practice, you won't even be able to create
this many fibers, because physical memory is also a limiting factor).
Therefore, the 1MB reserved stack size (RSS) must be set to a smaller
value: the coroutine stack size requested for the module, plus
the \ttt{extra-stack-kb} amount for Cmdenv/Tkenv -- which makes
about 16K with Cmdenv, and about 48K when using Tkenv.
Unfortunately, the CreateFiber() Win32 API doesn't allow the RSS to be
specified. The more advanced CreateFiberEx() API which accepts RSS as
parameter is unfortunately only available from Windows XP.

The alternative is the stacksize parameter stored in the EXE header,
which can be set
via the STACKSIZE .def file parameter, via the /stack linker option,
or on an existing executable using the editbin /stack utility.
This parameter specifies a common RSS for the main program stack,
fiber and thread stacks. 64K should be enough. This is the way
simulation executable should be created: linked with the /stack:65536
option, or the /stack:65536 parameter applied using editbin later.
For example, after applying the editbin /stacksize:65536 command to
dyna.exe, I was able to successfully run the Dyna sample with 8000
Client modules on my Win2K PC with 256M RAM (that means about 12000
modules at runtime, including about 4000 dynamically created modules.)


\subsubsection{``Segmentation fault''}

On Unix, if you set the total stack size higher, you may get a
segmentation fault during network setup\index{segmentation fault} (or
during execution if you use dynamically created modules) for exceeding
the operating system limit for maximum stack size. For example, in
Linux 2.4.x, the default stack limit is 8192K (that is, 8MB). The
\fprog{ulimit} shell command can be used to modify the
resource limits, and you can raise the allowed maximum stack size
up to 64M.

\begin{verbatim}
$ ulimit -s 65500
$ ulimit -s
65500
\end{verbatim}

Further increase is only possible if you're root.
Resource limits are inherited by child processes.
The following sequence can be used under Linux to get a shell with
256M stack limit:

\begin{verbatim}
$ su root
Password:
# ulimit -s 262144
# su andras
$ ulimit -s
262144
\end{verbatim}

If you do not want to go through the above process at each login, you
can change the limit in the PAM configuration files. In Redhat Linux
(maybe other systems too), add the following line to
\ttt{/etc/pam.d/login}:

\begin{verbatim}
session    required    /lib/security/pam_limits.so
\end{verbatim}

and the following line to \ttt{/etc/security/limits.conf}:

\begin{verbatim}
*    hard    stack    65536
\end{verbatim}

\begin{sloppypar}
A more drastic solution is to recompile the kernel with a larger stack
limit. Edit \ttt{/usr/src/linux/include/linux/sched.h} and increase
\ttt{\_STK\_LIM} from \ttt{(8*1024*1024)} to \ttt{(64*1024*1024)}.
\end{sloppypar}

Finally, it you're tight with memory, you can switch to Cmdenv. Tkenv
increases the stack size of each module by about 32K\index{stack!for
  Tkenv} so that user interface code that is called from a
simple module's context can be safely executed.
Cmdenv does not need that much extra stack.


\subsubsection{Eventually...}

Once you get to the point where you have to adjust the total stack size
to get your program running,
you should probably consider transforming (some of) your \fname{activity()}
simple modules to \fname{handleMessage()}. \fname{activity()} does not
scale well for large simulations.



\subsection{Memory leaks and crashes}

The most common problems in C++ are associated with memory allocation
(usage of \ttt{new} and \ttt{delete}):

\begin{itemize}
   \item{\textit{memory leaks,} that is, forgetting to delete objects
     or memory blocks no longer used;}
   \item{\textit{crashes,} usually due to referring to an already deleted
     object or memory block, or trying to delete one for a second time;}
   \item{\textit{heap corruption} (enventually leading to crash) due to
     overrunning allocated blocks, i.e. writing past the end of an allocated
     array.}
\end{itemize}

By far the most common ways leaking memory in simulation programs
is by not deleting messages (\cclass{cMessage} objects or subclasses).
Both Tkenv and Cmdenv are able to display the number of messages
currently in the simulation,
see e.g. section \ref{sec:ch-run-sim:interpreting-cmdenv-output}.
If you find that the number of messages is steadily increasing,
you need to find where the message objects are. You can do so
by selecting \textit{Inspect|From list of all objects...} from
the Tkenv menu, and reviewing the list in the dialog that pops up.
(If the model is large, it may take a while for the dialog to appear.)

If the number of messages is stable, it is still possible
you're leaking other \cclass{cOwnedObject}-based objects. You can
also find them using Tkenv's \textit{Inspect|From list of all objects...}
function.

If you're leaking non-\cclass{cOwnedObject}-based objects or just
memory blocks (\ttt{struct}s, \ttt{int}/\ttt{double}/\ttt{struct} arrays,
etc, allocated by \ttt{new}), you cannot find them via Tkenv.
You'll probably need a specialized memory debugging tool like
the ones described below.

\subsubsection{Memory debugging tools}

If you suspect that you may have memory allocation problems
(crashes associated with double-deletion or accessing already
deleted block, or memory leaks), you can use specialized tools
to track them down.

By far the most efficient, most robust and most versatile tool
is \textit{Valgrind}, originally developed for debugging KDE.

Other memory debuggers are \textit{NJAMD}, \textit{MemProf},
\textit{MPatrol}, \textit{dmalloc} and \textit{ElectricFence}.
Most of the above tools support tracking down memory leaks as well as
detecting double deletion, writing past the end of an allocated block, etc.

A proven commercial tool \textit{Rational Purify}. It has
a good reputation and proved its usefulness many times.


\subsection{Simulation executes slowly}

What can you do if the simulation executes much slower than you expect?
The best advice that can be given here is that you should
\tbf{use a good profiler} to find out how much time is spent in each
part of the program. Do not make the mistake of omitting this step,
thinking that you know "which part is slow"! Even for experienced
programmers, profiling session is all too often full of surprises.
It often turns out that lots of CPU time is spent in completely
innocent-looking statements, while the big and complex algorithm
doesn't take nearly as much time as expected. \textit{Don't assume anything
-- profile before you optimize!}
    \footnote{And before blaming the simulation kernel for poor performance...}

A really impressive profiler on Linux is the \textit{Valgrind}-based
\textit{callgrind}, and its visualizer \textit{KCachegrind}.
Unfortunately it won't be ported to Windows anytime soon.
On Windows, you're out of luck -- commercial products may help, or,
port your simulation to Linux. The latter goes usually much smoother
than one would expect.


%
%Use a profiler! KCachegrind.
%
%EV trick.
%
%Here are a few tips that can help you make the simulation faster:
%\begin{itemize}
%  \item{Use message subclassing instead of adding \fname{cPar}'s to messages.}
%  \item{Try to minimize message creations and deletions. Reuse
%    messages if possible.}
%  \item{Turn off the display of screen messages when you run the
%    simulation.  You can do this in the ini file. Alternatively, you
%    can place \ttt{\#ifdef}s around your \texttt{ev<<} and
%    \index{ev.printf()} calls and turn off the define when compiling
%    the simulation for speed.}
%  \item{Store the module parameters in local variables to avoid
%    calling \cclass{cPar} member functions every time.}
%\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "usman"
%%% End:

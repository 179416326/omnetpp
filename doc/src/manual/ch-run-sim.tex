\chapter{Running Simulations}
\label{cha:run-sim}

\section{Introduction}

This chapter describes how to run simulations. It covers basic usage,
user interfaces, batch runs, how to use Akaroa, and also explains
how to solve the most common errors.

\subsection{Running a simulation executable}
\label{sec:ch-run-sim:running}

By default, the output of an \fprog{opp\_makemake}-generated makefile is
a simulation executable that can be run directly. In simple cases,
this executable can be run without command-line arguments, but usually
one will need to specify options to specify what ini file to use,
which user interface to activate, where to load NED files from, and so on.

\subsubsection{Getting help}

The following sections describe the most frequently used command-line
options. To get a complete list of supported command line options, run
a simulation executable (or \fprog{opp\_run}) with the \ttt{-h} option.

\begin{commandline}
$ ./fifo -h
\end{commandline}

\subsubsection{Specifying ini files}

The default ini file is \ffilename{omnetpp.ini}, and is
loaded if no other ini file is given on the command line.

Ini files can be specified both as plain arguments and with the \ttt{-f}
option, so the following two commands are equivalent:

\begin{commandline}
$ ./fifo experiment.ini common.ini
$ ./fifo -f experiment.ini -f common.ini
\end{commandline}

Multiple ini files can be given, and their contents will get merged. This
allows for partitioning the configuration into separate files, for example
to simulation options, module parameters and result recording options.


\subsubsection{Specifying the NED path}

NED files are loaded from directories listed on the NED path. More precisely,
they are loaded from the listed directories and their whole subdirectory trees.
Directories are separated with a semicolon (\ttt{;}).

\begin{note}
Semicolon is used as separator on both Unix and Windows.
\end{note}

The NED path can be specified in several ways:
\begin{itemize}
  \item using the \ttt{NEDPATH} environment variable
  \item using the \ttt{-n} command-line option
  \item in ini files, with the \fconfig{ned-path} configuration option
\end{itemize}

NED path resolution rules are as follows:
\begin{itemize}
  \item {\opp} checks for NED path specified on the command line with the \ttt{-n} option
  \item if not found on the command line, it checks for the NEDPATH environment variable
  \item the \fconfig{ned-path} entry from the ini file gets appended to the result of the above steps
  \item if the result is still empty, it falls back to "." (the current directory)
\end{itemize}


\subsubsection{Selecting a user interface}

{\opp} simulations can be run under different user interfaces.
Currently the following user interfaces are supported:

\begin{itemize}
  \item Tkenv: Tcl/Tk-based graphical, windowing user interface
  \item Cmdenv: command-line user interface for batch execution
\end{itemize}

You would typically test and debug your simulation under Tkenv,
then run actual simulation experiments from the command line or
shell script, using Cmdenv. Tkenv is also better suited for educational or
demonstration purposes.

Both Tkenv and Cmdenv are provided in the form of a library, and
you may choose between them by linking one or both into your
simulation executable. (Creating the executable was described in
chapter \ref{cha:building-simulation-programs}). Both user interfaces
are supported on Unix and Windows platforms.

You can choose which runtime environment is included in your simulation executable when
you generate your makefile. By default both Tkenv and Cmdenv is linked in so you can choose
between them during runtime, but it is possible to specify only a single user interface with the
\ttt{-u Cmdenv} or \ttt{-u Tkenv} option on the \fprog{opp\_makemake} command line. This can be
useful if you intend to run your simulations on a machine where Tcl/Tk is not installed.

By default, Tkenv will be used if both runtime environment is present in your executable,
but you can override this with the \ttt{user-interface=Cmdenv} in your ini file or by
specifying \ttt{-u Cmdenv} on the command line. If both the config option and
the command line option are present, the command line option takes precedence.

\subsubsection{Selecting a configuration and run number}

Configurations can be selected with the \ttt{-c <configname>} command line option.
If you do not specify the configuration and you are running under:

\begin{itemize}
  \item Tkenv: the runtime environment will prompt you to choose one.
  \item Cmdenv: the \ttt{General} configuration will be executed.
\end{itemize}

User interfaces may support the \ttt{-r runnumber} option to select runs,
either one or more, depending on the type of the user interface.

There are several command line options to get information about the iteration
variables and the number of runs in the configurations:

\begin{itemize}
  \item \ttt{-a} -- Prints all configuration names and the number of runs in them.
  \item \ttt{-x <configname>} -- Prints the number of runs available in the given configuration.
  \item \ttt{-g} -- Prints the unrolled configuration (together with the -x option) and
                    expands the iteration variables.
  \item \ttt{-G} -- Prints even more details than -g.
\end{itemize}


\subsubsection{Loading extra libraries}

{\opp} allows you to load shared libraries at runtime. This means that you can create
simulation models as a shared library and load the model later into a different executable without
the need to explicitly link against that library. This approach has several advantages.

\begin{itemize}
  \item It is possible to distribute the model as a shared library. Others may be able to use
  it without recompiling it.
  \item You can split a large model into smaller, reusable components.
  \item You can mix several models (even from different projects)
    without the need of linking or compiling.
\end{itemize}

Use the \ttt{-l libraryname} command line option to load a library dynamically at run time.
{\opp} will attempt to load it using the \ffunc{dlopen()} or \ffunc{LoadLibrary()} functions and
automatically registers all simple modules in the library.

The prefix and suffix from the library name can be omitted (the extension (\ttt{.dll, .so, .dylib} and also
the common \ttt{lib} prefix on unix systems). This means that you can specify the library name in a
platform independent way (name.dll, libname.dll, libname.so and libname.dylib can be loaded with \ttt{-l name}).

It is also possible to specify the libraries to be loaded in the ini file with the \ttt{load-libs=} config option.
The values from the command line and the config file will be merged.

\begin{note}
  Runtime loading is not needed if your executable or shared lib was
  already linked against the library in question. In that case,
  the platform's dynamic loader will automatically load the library.
\end{note}

\begin{note}
  You must ensure that the library can be accessed by {\opp} . You have to specify
  the path with your library name (pre- and postfixes of the library filename
  still can be omitted) or adjust your shared library path according to your OS.
  (On Windows set the PATH, on Unix set LD\_LIBRARY\_PATH and on Mac OS X
  set the DYLD\_LIBRARY\_PATH as needed.)
\end{note}

\subsection{Running a shared library}

Shared libraries can be run using the \fprog{opp\_run} program.
Both \fprog{opp\_run} and simulation executables are capable of
loading additional shared libraries; actually, \fprog{opp\_run}
is nothing else than an empty simulation executable.

Example:
\begin{commandline}
opp_run -l mymodel
\end{commandline}

The above example will load the model found in \ttt{libmymodel.so} and execute it.

\subsection{Controlling the run}

There are several useful configuration options that control how a simulation is run.

\begin{itemize}
  \item \fconfig{cmdenv-express-mode} -- Provides only minimal status updates on the console.
  \item \fconfig{cmdenv-interactive} -- Allows asking interactively for missing
        parameter values.
  \item \fconfig{cmdenv-status-frequency} -- How often the status is written to the console.
  \item \fconfig{cpu-time-limit} -- Limit how long the simulation should run (in wall clock time)
  \item \fconfig{sim-time-limit} -- Limit how long the simulation should run (in simulation time)
  \item \fconfig{debug-on-errors} -- If the runtime detects any error it will generate a breakpoint
        so you will be able to check the location and the context of the problem in your debugger.
  \item \fconfig{fingerprint} -- The simulation kernel computes a checksum while running the simulation.
          It is calculated from the module id and from the current simulation time of each event.
          If you specify the \fconfig{fingerprint} option in the config file, the simulation runtime will
          compare the computed checksum with the provided one. If there is a difference it will
          generate an error. This feature is very useful if you make some cosmetic changes to your
          source and want to be reasonable sure that your changes did not altered the behaviour
          f the model.
          \begin{warning}
          The value of the calculated fingerprint is heavily dependent on the accuracy of the floating
          point arithmetic. There are differences between the floating point handling of AMD and Intel CPUs.
          Also running under a processor emulator software like \fconfig{valgrind} may produce 
          different fingerprint. This is normal.
          \end{warning}
  \item \fconfig{record-eventlog} -- You can turn on the recording of the simulator events. The
           resulting file can be analyzed later in the IDE with the sequence chart tool.
\end{itemize}

\begin{note}
  It is possible to specify a configuration option also on command line (in which case the
  command line takes precedence). You should prefix the option name with a double
  dash (-{}-) and should not put any spaces around the equal sign
  (e.g. \ttt{-{}-debug-on-errors=true})
\end{note}

To get the list of all possible configuration options type:

\begin{commandline}
opp_run -h config
\end{commandline}


\section{Cmdenv: the command-line interface}

The command line user interface\index{command line user interface} is
a small, portable and fast user interface that compiles and runs on
all platforms. Cmdenv\index{Cmdenv} is designed primarily for batch execution.

Cmdenv simply executes some or all simulation runs that are described
in the configuration file. If one run stops with an error message,
subsequent ones will still be executed. The runs to be executed can be
passed via command-line argument or in the ini file.

\subsection{Example run}

When run the Fifo example under Cmdenv, you should see
something like this:

\begin{commandline}
$ ./fifo -u Cmdenv -c Fifo1

OMNeT++ Discrete Event Simulation  (C) 1992-2008 Andras Varga, OpenSim Ltd.
Version: 4.0, edition: Academic Public License -- NOT FOR COMMERCIAL USE
See the license for distribution terms and warranty disclaimer
Setting up Cmdenv...
Loading NED files from .: 5

Preparing for running configuration Fifo1, run #0...
Scenario: $repetition=0
Assigned runID=Fifo1-0-20090104-12:23:25-5792
Setting up network 'FifoNet'...
Initializing...
Initializing module FifoNet, stage 0
Initializing module FifoNet.gen, stage 0
Initializing module FifoNet.fifo, stage 0
Initializing module FifoNet.sink, stage 0

Running simulation...
** Event #1   T=0   Elapsed: 0.000s (0m 00s)  0% completed
     Speed:     ev/sec=0   simsec/sec=0   ev/simsec=0
     Messages:  created: 2   present: 2   in FES: 1
** Event #232448   T=11719.051014922336   Elapsed: 2.003s (0m 02s)  3% completed
     Speed:     ev/sec=116050   simsec/sec=5850.75   ev/simsec=19.8351
     Messages:  created: 58114   present: 3   in FES: 2
...
** Event #7206882   T=360000.52066583684   Elapsed: 78.282s (1m 18s)  100% completed
     Speed:     ev/sec=118860   simsec/sec=5911.9   ev/simsec=20.1053
     Messages:  created: 1801723   present: 3   in FES: 2

<!> Simulation time limit reached -- simulation stopped.

Calling finish() at end of Run #0...
End.
\end{commandline}

As Cmdenv runs the simulation, periodically it prints the sequence number
of the current event, the simulation time, the elapsed (real) time,
and the performance of the simulation (how many events are processed per
second; the first two values are 0 because there wasn't enough data
for it to calculate yet). At the end of the simulation, the \ffunc{finish()}
methods of the simple modules are run, and the output from them are displayed.
On my machine this run took 34 seconds. This Cmdenv output can be
customized via \ffilename{omnetpp.ini} entries. The output file \ffilename{results/Fifo1-0.vec}
contains vector data recorded during simulation (here, queueing times),
and it can be processed using the IDE or other tools.

\subsection{Command-line switches}

The command line environment allows you to specify more than one run by
using the \ttt{-r 2,4,6..8} format. See \ref{sec:ch-run-sim:batch-execution}
for more information about running simulation batches.

\subsection{Cmdenv ini file options}
\label{sec:ch-run-sim:cmdenv-section}

\fpar{cmdenv-runs-to-execute} specifies which simulation runs should be executed.
It accepts a comma-separated list of run numbers or run number ranges, e.g.
\ttt{1,3..4,7..9}. If the value is missing, Cmdenv executes all runs that have
ini file sections; if no runs are specified in the ini file, Cmdenv does one run.
The -r command line option overrides this ini file setting.


Cmdenv can be executed in two modes, selected by the \fconfig{cmdenv-express-mode}
ini file option:

\begin{itemize}
    \item \tbf{Normal} (non-express) mode is for debugging: detailed information
        will be written to the standard output (event banners, module output,
        etc).
    \item \tbf{Express} mode can be used for long simulation runs: only
        periodical status update is displayed about the progress of the
        simulation.
\end{itemize}

\fconfig{cmdenv-performance-display} affects express mode only: it controls
whether to print performance information. Turning it on results in a 3-line
entry printed on each update, containing ev/sec, simsec/sec, ev/simsec,
number of messages created/still present/currently scheduled in FES\index{FES}.

For a full list of options, see the ones beginning with \ttt{cmdenv} in
Appendix \ref{cha:config-options}.


\subsection{Interpreting Cmdenv output}
\label{sec:ch-run-sim:interpreting-cmdenv-output}

When the simulation is running in ``express'' mode with detailed
performance display enabled, Cmdenv periodically outputs a three-line
status info about the progress of the simulation.
The output looks like this:

\begin{commandline}
...
** Event #250000   T=123.74354 ( 2m  3s)    Elapsed: 0m 12s
     Speed:     ev/sec=19731.6   simsec/sec=9.80713   ev/simsec=2011.97
     Messages:  created: 55532   present: 6553   in FES: 8
** Event #300000   T=148.55496 ( 2m 28s)    Elapsed: 0m 15s
     Speed:     ev/sec=19584.8   simsec/sec=9.64698   ev/simsec=2030.15
     Messages:  created: 66605   present: 7815   in FES: 7
...
\end{commandline}

The first line of the status display (beginning with \ttt{**})
contains:

\begin{itemize}
   \item{how many events have been processed so far}
   \item{the current simulation time (T), and}
   \item{the elapsed time (wall clock time) since the beginning of the simulation run.}
\end{itemize}

The second line displays info about simulation performance:

\begin{itemize}
   \item{\ttt{ev/sec} indicates \textit{performance}: how many events are processed
     in one real-time second.  On one hand it depends on your hardware
     (faster CPUs process more events per second), and on the other hand
     it depends on the complexity (amount of calculations) associated
     with processing one event. For example, protocol simulations tend to require
     more processing per event than e.g. queueing networks, thus
     the latter produce higher ev/sec values.
     In any case, this value is independent of the size (number of modules) in your model.}
   \item{\ttt{simsec/sec} shows \textit{relative speed} of the simulation, that is,
     how fast the simulation is progressing compared to real time, how many
     simulated seconds can be done in one real second. This value virtually depends
     on everything: on the hardware, on the size of the simulation model,
     on the complexity of events, and the average simulation time between events as well.}
   \item{\ttt{ev/simsec} is the \textit{event density}: how many events are
     there per simulated second. Event density only depends on the simulation model,
     regardless of the hardware used to simulate it: in a cell-level ATM simulation
     you'll have very hight values ($10^9$), while in a bank teller simulation
     this value is probably well under 1. It also depends on the size of your
     model: if you double the number of modules in your model, you can expect
     the event density double, too.}
\end{itemize}

The third line displays the number of messages, and it is important
because it may indicate the `health' of your simulation.

\begin{itemize}
   \item{\ttt{Created}: total number of message objects created since the
     beginning of the simulation run. This does not mean that this many message
     object actually exist, because some (many) of them may have been deleted
     since then. It also does not mean that \textit{you} created all those
     messages -- the simulation kernel also creates messages for its own use
     (e.g. to implement \ttt{wait()} in an \ttt{activity()} simple module).}
   \item{\ttt{Present}: the number of message objects currently present
     in the simulation model, that is, the number of messages created (see above)
     minus the number of messages already deleted. This number includes
     the messages in the FES\index{FES}.}
   \item{\ttt{In FES}: the number of messages currently scheduled in the
     Future Event Set.}
\end{itemize}


The second value, the number of messages present is more useful than
perhaps one would initially think. It can be an indicator of the `health' of the simulation:
if it is growing steadily, then either you have a memory leak and losing
messages (which indicates a programming error), or the network you simulate is
overloaded and queues are steadily filling up (which might indicate wrong input
parameters).

Of course, if the number of messages does not increase, it does not mean
that you do \textit{not} have a memory leak (other memory leaks are also
possible). Nevertheless the value is still useful, because by far the
most common way of leaking memory in a simulation is by not deleting messages.



\section{Tkenv: the graphical user interface}

Tkenv\index{Tkenv} is a portable graphical windowing user interface.
Tkenv supports interactive execution of the simulation, tracing and
debugging\index{simulation!debugging}. Tkenv is recommended in the
development stage of a simulation or for presentation and educational
purposes, since it allows one to get a detailed picture of the state
of simulation at any point of execution and to follow what happens
inside the network.

\subsection{Command-line switches}

A simulation program built with Tkenv accepts all the general command line
switches\index{command line switches}. In addition the \ttt{-r runnumber}
option allows only specifying a single run. Multiple runs are not supported.

Tkenv configuration options:
\begin{itemize}
  \item{\fconfig{tkenv-default-config}:
    Specifies which config Tkenv should set up automatically on startup. The
    default is to ask the user.}

  \item{\fconfig{tkenv-default-run}: Specifies which run (of the default
    config, see tkenv-default-config) Tkenv
    should set up automatically on startup. The default is to ask the user.}

  \item{\fconfig{tkenv-extra-stack}:
    Specifies the extra amount of stack that is reserved for each activity()
    simple module when the simulation is run under Tkenv.}

  \item{\fconfig{tkenv-image-path}: Specifies the path for loading module icons.}

  \item{\fconfig{tkenv-plugin-path}:
    Specifies the search path for Tkenv plugins. Tkenv plugins are .tcl files
    that get evaluated on startup.}
\end{itemize}

Tkenv specific configuration options can be specified also on command line
by prefixing them with double dash (e.g -{}-tkenv-option=value). See
Appendix \ref{cha:config-options} for the list of possible configuration options.

\begin{note}
The usage of the Tkenv user interface is detailed in the {\opp}  User Guide's Tkenv
chapter.
\end{note}

\section{Batch execution}
\label{sec:ch-run-sim:batch-execution}

Once your model works reliably, you'll usually want to run several
simulations. You may want to run the model with various
parameter settings, or you may want \textit{(should want?)} to
run the same model with the same parameter settings but with
different random number generator seeds, to achieve statistically
more reliable results.

Running a simulation several times by hand can easily become tedious,
and then a good solution is to write a control script that
takes care of the task automatically. Unix shell is
a natural language choice to write the control script in,
but other languages like Perl, Matlab/Octave, Tcl, Ruby might also have
justification for this purpose.

Of course before running simulation batches you must set a condition to
stop your simulation. This is usually a time limit set by the
\fconfig{sim-time-limit} configuration option, but you can limit your simulation
by using wall clock time (\fconfig{cpu-time-limit}) or by directly ending a
simulation with an API call if some condition is true.

\subsection{Using Cmdenv}

  To execute more than one run using the Cmdenv use the \ttt{-r} option
  and specify the runs in a comma separated format 1,2,4,9..11 or you may leave
  out the \ttt{-r} option to execute all runs in the experiment.

\begin{warning}
  Although it is very convenient, we do not recommended to use this method for
  running simulation batches. Specifying more than one runnumber
  would run these simulations in the same process. This method is more prone to C++ programming
  errors. A failure in a single run may stop and kill all the runs following it. If you want
  to execute more than one run we recommend to run each of them in a separate process.
  Use the \fprog{opp\_runall} for this purpose.
\end{warning}


\subsection{Using shell scripts}

The following script executes a simulation named \ttt{wireless}
several times, with parameters for the different runs
given in the \ttt{runs.ini} file.

Before you are executing your simulation batch, you may check how many
runs are available in the configuration you are using. Use the
\ttt{-x config} command line option to print the number of runs or
add the \ttt{-g} to get more details.

\begin{filelisting}
#! /bin/sh
./wireless -f runs.ini -r 1
./wireless -f runs.ini -r 2
./wireless -f runs.ini -r 3
./wireless -f runs.ini -r 4
...
./wireless -f runs.ini -r 10
\end{filelisting}

To run the above script, type it in a text file called e.g. \ttt{run},
give it \ttt{x} (executable) permission using \ttt{chmod},
then you can execute it by typing \ttt{./run}:

\begin{commandline}
$ chmod +x run
$ ./run
\end{commandline}

You can simplify the above script by using a \textit{for} loop.
In the example below, the variable \ttt{i} iterates through
the values of list given after the \ttt{in} keyword.
It is very practical, since you can leave out or add runs,
or change the order of runs by simply editing the list --
to demonstrate this, we skip run 6, and include run 15 instead.

\begin{filelisting}
#! /bin/sh
for i in 3 2 1 4 5 7 15 8 9 10; do
   ./wireless -f runs.ini -r $i
done
\end{filelisting}

If you have many runs, you can use a C-style loop:

\begin{filelisting}
#! /bin/sh
for ((i=1; $i<50; i++)); do
   ./wireless -f runs.ini -r $i
done
\end{filelisting}

\subsection{Using opp\_runall}

{\opp} has a utility program called \fprog{opp\_runall} which
allows you to execute a simulation batch in command line mode.
You must specify the whole command line you would use to run
your batch in Cmdenv. There are advantages running your batches
this way:
\begin{itemize}
  \item Each simulation run executes in a separate operating system process.
        This means that a crash because of a programming error does not affect
        the outcome of the other runs. They are totally independent of each other.
  \item If you happen to have a multi core/processor machine, you can take advantage
        of the processing power by running sevaral runs parallel.
\end{itemize}

The command basically creates a makefile which contains
a separate target for each run. By default the makefile will be executed causing each
target to run. You can give additional options to the \fprog{opp\_runall} command to
activate parallel building. The \ttt{-j} option can be used to specify the maximum number
of parallel runs allowed.

\begin{warning}
  Use the parallel execution option only if you have enough memory to run several simulations
  side by side. If you run out of memory your operating system will start swapping and the overall
  performance of the system will be greatly reduced. Always specify the number of processes
  after the \ttt{-j} option otherwise the \fprog{make} program will try to start \textit{all}
  runs at the same time. As a rule of thumb: if you have 4 cores (and enough memory), use \ttt{-j4}.
\end{warning}

The form of the command is:
\begin{commandline}
opp_runall -j2 ./aloha -u Cmdenv -c PureAlohaExperiment -r 0..23
\end{commandline}

You can use the \ttt{-x ConfigName -g} command line options with your simulation to
check the number of available runs.

Using the \ttt{-{}-export filename} option only generates the \ttt{makefile}, but does not start it.
You can run your batch later by invoking the generated makefile.

%% TODO
%%\subsection{Using Xgrid}


\section{Akaroa support: Multiple Replications in Parallel}
\label{sec:ch-run-sim:akaroa}
\index{Akaroa}
\index{Multiple Replications in Parallel}

\subsection{Introduction}

Typical simulations are Monte-Carlo simulations: they use
(pseudo-)random numbers to drive the simulation model.
For the simulation to produce statistically reliable results,
one has to carefully consider the following:

\begin{itemize}
  \item{When is the initial transient over, when can we start
    collecting data? We usually do not want to include the
    initial transient when the simulation is still ``warming up.''}
  \item{When can we stop the simulation? We want to wait long enough
    so that the statistics we are collecting can ``stabilize'',
    can reach the required sample size to be statistically trustable.}
\end{itemize}

Neither questions are trivial to answer. One might just suggest
to wait ``very long'' or ``long enough''. However, this is neither
simple (how do you know what is ``long enough''?) nor practical
(even with today's high speed processors simulations of modest complexity
can take hours, and one may not afford multiplying runtimes by,
say, 10, ``just to be safe.'') If you need further convincing,
please read \cite{Pawlikowsky02} and be horrified.

A possible solution is to look at the statistics while the simulation
is running, and decide at runtime when enough data have been
collected for the results to have reached the required accuracy.
One possible criterion is given by the confidence level,
more precisely, by its width relative to the mean.
But ex ante it is unknown how many observations have to be collected
to achieve this level -- it must be determined runtime.


\subsection{What is Akaroa}

Akaroa \cite{Akaroa99} addresses the above problem.
According to its authors, Akaroa (Akaroa2) is a ``fully automated
simulation tool designed for running distributed stochastic simulations
in MRIP scenario'' in a cluster computing environment.

MRIP stands for \textit{Multiple Replications in Parallel}.
In MRIP, the computers of the cluster run independent replications
of the whole simulation process (i.e. with the same parameters but
different seed for the RNGs (random number generators)),
generating statistically equivalent streams of simulation output data.
These data streams are fed to a global data analyser responsible for
analysis of the final results and for stopping the simulation
when the results reach a satisfactory accuracy.

The independent simulation processes run independently of one another
and continuously send their observations to the central analyser
and control process. This process \textit{combines} the independent data streams,
and calculates from these observations an overall estimate of the mean value
of each parameter.
Akaroa2 decides by a given confidence level and precision
whether it has enough observations or not. When it judges that is
has enough observations it halts the simulation.

If \textit{n} processors are used, the needed simulation execution time
is usually \textit{n} times smaller compared to a one-processor
simulation (the required number of observations are produced sooner).
Thus, the simulation would be sped up approximately in proportion
to the number of processors used and sometimes even more.

Akaroa was designed at the University of Canterbury in Christchurch, New Zealand
and can be used free of charge for teaching and non-profit research activities.


\subsection{Using Akaroa with {\opp}}

\subsubsection{Akaroa}

Before the simulation can be run in parallel under Akaroa, you have to
start up the system:

\begin{itemize}
  \item{Start \ttt{akmaster} running in the background on some host.}
  \item{On each host where you want to run a simulation engine,
     start \ttt{akslave} in the background.}
\end{itemize}

Each \ttt{akslave} establishes a connection with the \ttt{akmaster}.

Then you use \ttt{akrun} to start a simulation. \ttt{akrun} waits
for the simulation to complete, and writes a report of the results
to the standard output. The basic usage of the \ttt{akrun} command is:

\begin{commandline}
akrun -n num_hosts command [argument..]
\end{commandline}

where \textit{command} is the name of the simulation you want to start.
Parameters for Akaroa are read from the file named \ttt{Akaroa} in
the working directory. Collected data from the processes are
sent to the \ttt{akmaster} process, and when the required precision
has been reached, \ttt{akmaster} tells the simulation processes to
terminate. The results are written to the standard output.

The above description is not detailed enough help you
set up and successfully use Akaroa -- for that you need to read the
Akaroa manual.

\subsubsection{Configuring {\opp} for Akaroa}

First of all, you have to compile {\opp} with Akaroa support enabled.

The {\opp} simulation must be configured in \ffilename{omnetpp.ini}
so that it passes the observations to Akaroa. The simulation model itself does
not need to be changed -- it continues to write
the observations into output vectors (\cclass{cOutVector} objects,
see chapter \ref{cha:the-simulation-library}). You can place some of
the output vectors under Akaroa control.

You need to add the following to \ffilename{omnetpp.ini}:

\begin{inifile}
[General]
rng-class = "cAkaroaRNG"
outputvectormanager-class = "cAkOutputVectorManager"
\end{inifile}

These lines cause the simulation to obtain random numbers from Akaroa,
and allows data written to selected output vectors to be passed to Akaroa's
global data analyser.
    \footnote{For more details on the plugin mechanism these settings make use of,
    see section \ref{sec:ch-plugin-exts:customization}.}

Akaroa's RNG is a Combined Multiple Recursive pseudorandom
number generator (CMRG) with a period of approximately $2^{191}$
random numbers, and provides a unique stream of random numbers
for every simulation engine. It is vital to obtain random numbers
from Akaroa: otherwise, all simulation processes would run with the same
RNG seeds, and produce exactly the same results!

Then you need to specify which output vectors you want to
be under Akaroa control. By default, all output vectors are under Akaroa
control; the

\begin{inifile}
<modulename>.<vectorname>.with-akaroa = false
\end{inifile}

setting can be used to make Akaroa ignore specific vectors.
You can use the \ttt{*}, \ttt{**} wildcards here (see
section \ref{sec:ch-config-sim:wildcards}). For example,
if you only want a few vectors be placed under Akaroa,
you can use the following trick:

\begin{inifile}
<modulename>.<vectorname1>.with-akaroa = true
<modulename>.<vectorname2>.with-akaroa = true
...
**.*.with-akaroa = false  # catches everything not matched above
\end{inifile}


\subsubsection{Using shared file systems}
\label{sec:run-sim:using-shared-filesystems}

It is usually practical to have the same physical disk mounted (e.g. via NFS or Samba)
on all computers in the cluster. However, because all {\opp} simulation
processes run with the same settings, they would overwrite each other's
output files (e.g. \ttt{omnetpp.vec}, \ttt{omnetpp.sca}).
Your can prevent this from happening using the
\fconfig{fname-append-host} ini file entry:

\begin{inifile}
[General]
fname-append-host = true
\end{inifile}

When turned on, it appends the host name to the names of the output
files (output vector, output scalar, snapshot files).



\section{Troubleshooting}

\subsection{Unrecognized configuration option}

If you receive an error message about unrecognized configuration
options you may use \ttt{-h config} or \ttt{-h configdetails} options
to display all possible configuration options and their descriptions.

\subsection{Stack problems}

\subsubsection{``Stack violation (\textit{FooModule} stack too small?) in module \textit{bar.foo}''}
\index{stack!too small}

{\opp} detected that the module has used more stack space than it has
allocated. The solution is to increase the stack for that module type.
You can call the \ffunc{getStackUsage()} from \ffunc{finish()} to find out
actually how much stack the module used.


\subsubsection{``Error: Cannot allocate \textit{nn} bytes stack for module \textit{foo.bar''}}

The resolution depends on whether you are using {\opp} on Unix or on Windows.

\textbf{Unix.}
If you get the above message, you have to increase the total stack
size\index{stack!size} (the sum of all coroutine stacks). You can do
so in \ffilename{omnetpp.ini}:

\begin{inifile}
[General]
total-stack-kb = 2048 # 2MB
\end{inifile}

There is no penalty if you set \fpar{total-stack-kb} too high. I
recommend to set it to a few K less than the maximum process stack
size allowed by the operating system (\fprog[ulimit]{ulimit -s}; see
next section).


\textbf{Windows.}
You need to set a \textit{low} (!) ``reserved stack size''
in the linker options, for example 64K (/stack:65536 linker flag) will do.
The ``reserved stack size'' is an attribute in the Windows exe
files' internal header. It can be set from the linker, or with
the \ttt{editbin} Microsoft utility. You can use the \ttt{opp\_stacktool}
program (which relies on another Microsoft utility called \ttt{dumpbin})
to display reserved stack size for executables.

You need a low reserved stack size because the Win32 Fiber API
which is the mechanism underlying \ffunc{activity()} uses
this number as coroutine stack size, and with 1MB being the default,
it is easy to run out of the 2GB possible address space (2GB/1MB=2048).

A more detailed explanation follows.
Each fiber has its own stack, by default 1MB (this is the ``reserved''
stack space -- i.e. reserved in the address space, but not the full
1MB is actually ``committed'', i.e. has physical memory assigned to it).
This means that a 2GB address space will run out after 2048 fibers,
which is way too few. (In practice, you won't even be able to create
this many fibers, because physical memory is also a limiting factor).
Therefore, the 1MB reserved stack size (RSS) must be set to a smaller
value: the coroutine stack size requested for the module, plus
the \ttt{extra-stack-kb} amount for Cmdenv/Tkenv -- which makes
about 16K with Cmdenv, and about 48K when using Tkenv.
Unfortunately, the CreateFiber() Win32 API doesn't allow the RSS to be
specified. The more advanced CreateFiberEx() API which accepts RSS as
parameter is unfortunately only available from Windows XP.

The alternative is the stacksize parameter stored in the EXE header,
which can be set
via the STACKSIZE .def file parameter, via the /stack linker option,
or on an existing executable using the editbin /stack utility.
This parameter specifies a common RSS for the main program stack,
fiber and thread stacks. 64K should be enough. This is the way
simulation executable should be created: linked with the /stack:65536
option, or the /stack:65536 parameter applied using editbin later.
For example, after applying the editbin /stacksize:65536 command to
dyna.exe, I was able to successfully run the Dyna sample with 8000
Client modules on my Win2K PC with 256M RAM (that means about 12000
modules at runtime, including about 4000 dynamically created modules.)


\subsubsection{``Segmentation fault''}

On Unix, if you set the total stack size higher, you may get a
segmentation fault during network setup\index{segmentation fault} (or
during execution if you use dynamically created modules) for exceeding
the operating system limit for maximum stack size. For example, in
Linux 2.4.x, the default stack limit is 8192K (that is, 8MB). The
\fprog{ulimit} shell command can be used to modify the
resource limits, and you can raise the allowed maximum stack size
up to 64M.

\begin{commandline}
$ ulimit -s 65500
$ ulimit -s
65500
\end{commandline}

Further increase is only possible if you're root.
Resource limits are inherited by child processes.
The following sequence can be used under Linux to get a shell with
256M stack limit:

\begin{commandline}
$ su root
Password:
# ulimit -s 262144
# su andras
$ ulimit -s
262144
\end{commandline}

If you do not want to go through the above process at each login, you
can change the limit in the PAM configuration files. In Redhat Linux
(maybe other systems too), add the following line to
\ttt{/etc/pam.d/login}:

\begin{filelisting}
session    required    /lib/security/pam_limits.so
\end{filelisting}

and the following line to \ttt{/etc/security/limits.conf}:

\begin{filelisting}
*    hard    stack    65536
\end{filelisting}

\begin{sloppypar}
A more drastic solution is to recompile the kernel with a larger stack
limit. Edit \ttt{/usr/src/linux/include/linux/sched.h} and increase
\ttt{\_STK\_LIM} from \ttt{(8*1024*1024)} to \ttt{(64*1024*1024)}.
\end{sloppypar}

Finally, it you're tight with memory, you can switch to Cmdenv. Tkenv
increases the stack size of each module by about 32K\index{stack!for
  Tkenv} so that user interface code that is called from a
simple module's context can be safely executed.
Cmdenv does not need that much extra stack.


\subsubsection{Eventually...}

Once you get to the point where you have to adjust the total stack size
to get your program running,
you should probably consider transforming (some of) your \ffunc{activity()}
simple modules to \ffunc{handleMessage()}. \ffunc{activity()} does not
scale well for large simulations.



\subsection{Memory leaks and crashes}

The most common problems in C++ are associated with memory allocation
(usage of \ttt{new} and \ttt{delete}):

\begin{itemize}
   \item{\textit{memory leaks,} that is, forgetting to delete objects
     or memory blocks no longer used;}
   \item{\textit{crashes,} usually due to referring to an already deleted
     object or memory block, or trying to delete one for a second time;}
   \item{\textit{heap corruption} (eventually leading to crash) due to
     overrunning allocated blocks, i.e. writing past the end of an allocated
     array.}
\end{itemize}

By far the most common ways leaking memory in simulation programs
is by not deleting messages (\cclass{cMessage} objects or subclasses).
Both Tkenv and Cmdenv are able to display the number of messages
currently in the simulation,
see e.g. section \ref{sec:ch-run-sim:interpreting-cmdenv-output}.
If you find that the number of messages is steadily increasing,
you need to find where the message objects are. You can do so
by selecting \textit{Inspect|From list of all objects...} from
the Tkenv menu, and reviewing the list in the dialog that pops up.
(If the model is large, it may take a while for the dialog to appear.)

If the number of messages is stable, it is still possible
you're leaking other \cclass{cOwnedObject}-based objects. You can
also find them using Tkenv's \textit{Inspect|From list of all objects...}
function.

If you're leaking non-\cclass{cOwnedObject}-based objects or just
memory blocks (\ttt{struct}s, \ttt{int}/\ttt{double}/\ttt{struct} arrays,
etc, allocated by \ttt{new}), you cannot find them via Tkenv.
You'll probably need a specialized memory debugging tool like
the ones described below.

\subsubsection{Memory debugging tools}

If you suspect that you may have memory allocation problems
(crashes associated with double-deletion or accessing already
deleted block, or memory leaks), you can use specialized tools
to track them down.

By far the most efficient, most robust and most versatile tool
is \textit{Valgrind}, originally developed for debugging KDE.

Other memory debuggers are \textit{NJAMD}, \textit{MemProf},
\textit{MPatrol}, \textit{dmalloc} and \textit{ElectricFence}.
Most of the above tools support tracking down memory leaks as well as
detecting double deletion, writing past the end of an allocated block, etc.

A proven commercial tool \textit{Rational Purify}. It has
a good reputation and proved its usefulness many times.

\subsection{Simulation executes slowly}

Check the following if you think your simulation is running too slow.

\begin{itemize}
  \item Turn on express mode with the \ttt{cmdenv-express-mode=true} configuration option.
  \item Be sure that event logging is turned off (\ttt{record-eventlog=false} configuration option).
  \item Turn of vector file recording if you do not absolutely need it (\ttt{**.vector-recording=false}).
  \item If you are running under Tkenv disable animation features, close inspectors,
        hide the timeline, hide object tree, turn off log filtering.
  \item Compile your code as release instead of debug (in some cases this can give you 5x speedup)
\end{itemize}


What can you do if the simulation executes much slower than you expect?
The best advice that can be given here is that you should
\tbf{use a good profiler} to find out how much time is spent in each
part of the program. Do not make the mistake of omitting this step,
thinking that you know "which part is slow"! Even for experienced
programmers, profiling session is all too often full of surprises.
It often turns out that lots of CPU time is spent in completely
innocent-looking statements, while the big and complex algorithm
doesn't take nearly as much time as expected. \textit{Don't assume anything
-- profile before you optimize!}

A great profiler on Linux is the \textit{Valgrind}-based
\textit{callgrind}, and its visualizer \textit{KCachegrind}.
Unfortunately it won't be ported to Windows anytime soon.
On Windows, you're out of luck -- commercial products may help, or,
port your simulation to Linux. The latter goes usually much smoother
than one would expect.


%
%Use a profiler! KCachegrind.
%
%EV trick.
%
%Here are a few tips that can help you make the simulation faster:
%\begin{itemize}
%  \item{Use message subclassing instead of adding \ffunc{cPar}'s to messages.}
%  \item{Try to minimize message creations and deletions. Reuse
%    messages if possible.}
%  \item{Turn off the display of screen messages when you run the
%    simulation.  You can do this in the ini file. Alternatively, you
%    can place \ttt{\#ifdef}s around your \ttt{ev<<} and
%    \index{ev.printf()} calls and turn off the define when compiling
%    the simulation for speed.}
%  \item{Store the module parameters in local variables to avoid
%    calling \cclass{cPar} member functions every time.}
%\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "usman"
%%% End:

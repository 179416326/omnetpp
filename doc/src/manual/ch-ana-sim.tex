\chapter{Analyzing Simulation Results}
\label{cha:analyzing-simulation-results}


\section{Result files}

\subsection{Results}

vector results, scalar results

unique run id

attributes, e.g. experiment-measurement-replication

The format of result files is documented in detail in \ref{cha:result-file-formats}.

\subsection{Output vectors}
\label{sec:ch-ana-sim:output-vectors}

Output vectors are time series data: values with timestamps.
You can use output vectors to record end-to-end delays or
round trip times of packets, queue lengths, queueing times,
link utilization, the number of dropped packets, etc. --
anything that is useful to get a full picture of what happened
in the model during the simulation run.

Output vectors are recorded from simple modules, by \cclass{cOutVector} objects
(see section \ref{sec:ch-sim-lib:coutvector}). Since output vectors usually
record a large amount of data, in \ttt{omnetpp.ini} you can disable vectors
or specify a simulation time interval for recording
(see section \ref{sec:ch-config-sim:outvectors}).

All \cclass{cOutVector} objects write to the same, common file.
The following sections describe the format of the file, and
how to process it.


\subsection{Format of output vector files}

An output vector file\index{output!vector file} contains several
series of data produced during simulation. The file is textual, and it
looks like this:

\begin{Verbatim}[commandchars=\\\{\}]
\textbf{net-1.vec:}
vector 1   "subnet[4].term[12]"  "response time"  TV
1  12.895  2355.66666666
1  14.126  4577.66664666
vector 2   "subnet[4].srvr"  "queue length"  TV
2  16.960  2.00000000000.63663666
1  23.086  2355.66666666
2  24.026  8.00000000000.44766536
\end{Verbatim}

There two types of lines: vector declaration lines (beginning with
the word \ttt{vector}), and data lines.
A \textit{vector declaration line} introduces a new output vector, and
its columns are: vector Id, module of creation, name of \cclass{cOutVector}
object, and multiplicity (usually 1). Actual data recorded in this
vector are on \textit{data lines} which begin with the vector Id.
Further columns on data lines are the simulation time and the recorded value.

vector data clustering for efficiency

indexed access

how to configure the IndexVectorFileManager (?)


\subsection{Scalar results}

Scalar results are recorded with \fname{recordScalar()} calls,
usually from the \ttt{finish()} methods of modules.


\subsubsection{Format of scalar files}

The corresponding output scalar file (by default, \fname{omnetpp.sca})
will look like this:

\begin{verbatim}
scalar "lan.hostA.mac" "frames sent"                99
scalar "lan.hostA.mac" "frames rcvd"                3088
scalar "lan.hostA.mac" "bytes sent"                 64869
scalar "lan.hostA.mac" "bytes rcvd"                 3529448
...
\end{verbatim}

Every \fname{record()} call generates one "scalar" line in the file.
(If you record statistics objects (\cclass{cStatictic} subclasses
such as \cclass{cStdDev}) via their \fname{record()} methods,
they'll generate several lines: mean, standard deviation, etc.)
In addition, several simulation runs can record their results into a single file --
this facilitates comparing them, creating x-y plots
(\textit{offered load vs throughput}-type diagrams), etc.



\section{The Analysis Tool in the Simulation IDE}

The Simulation IDE provides an Analysis Tool for analysis and visualization
of simulation results. The Analysis Tool lets you load several result files
at once, and presents their contents somewhat like a database. You can
browse the results, select the particular data you are interested in
(scalars, vectors, histograms), apply processing steps, and create various
charts or plots from them. Data selection, processing and charting steps
can be freely combined, resulting in a high degree of freedom.
These steps are grouped into and stored as "recipes", which get automatically
re-applied when new result files are added or existing files are
replaced. This automation spares the user lots of repetitive manual work,
without resorting to scripting.

The Analysis Tool is covered in detail in the User Guide.


\section{Scave Tool}

Much of the IDE Analysis Tool's functionality is available on the command
line as well, via the \fprog{scavetool} program. When \fprog{scavetool}
is invoked without arguments, it prints usage information:

\begin{verbatim}
scavetool <command> [options] <file>...
\end{verbatim}

\subsection{Filter command}

The result files can be filtered and processed by this command and the
result can be written into files as vector files, CSV files,
Matlab or Octave files.

The filter can be specified by the {\itshape -p <filter>} option.
The filter is one or more {\itshape <fieldname>(<pattern>)} expression
connected with AND, OR and NOT operators. The possible field names are:

\begin{itemize}
    \item\tbf{file}: full path of the result file
    \item\tbf{run}: run identifier
    \item\tbf{module}: module name
    \item\tbf{name}: vector name
    \item\tbf{attr:<runAttribute>}: value of an attribute of the run
                                   (e.g. experiment)
    \item\tbf{param:<moduleParameter>}: value of the parameter in the run
\end{itemize}

Processing operations can be applied to vectors by the
{\itshape -a <function>(<parameterlist>)} option. You can list
the available functions and their parameters by the {\itshape info} command.

The name and format of the output file can be given by the
{\itshape -O <file>} and {\itshape -F <formatname>} options, where
the formatname is one of:

\begin{itemize}
    \item\tbf{vec}: vector file (default)
    \item\tbf{csv}: CSV file
    \item\tbf{octave}: Octave text file
    \item\tbf{matlab}: Matlab script file
\end{itemize}

Examples:

\begin{verbatim}
scavetool filter -p "queuing time" -a winavg(10) -O out.vec in.vec
\end{verbatim}

Writes the window averaged queuing times stored in in.vec into out.vec.

\begin{verbatim}
scavetool filter -p "module(**.sink) AND
                    (\"queueing time\" OR \"transmission time\")"
                 -O out.csv -F csv in.vec
\end{verbatim}

Writes the queing and transmission times of sink modules into CSV files.
It generates a separate files for each vector named
\textit{out-1.csv}, \textit{out-2.csv}...
The generated file contains a header and two columns:

\begin{verbatim}
time,"Queue.sink.queueing time"
2.231807576851,0
7.843802235089,0
15.797137536721,3.59449
21.730758362277,6.30398
[...]
\end{verbatim}


\subsection{Index command}

If the index file was deleted or the vector file was modified, you need to
rebuild the index file before running the filter command.

Normally the vector data is written in blocks into the vector file.
However if the vector file was generated by an older version of the
\cclass{cOutputVectorManager} it might not be so. In this case you have
to specify the -r option to rearrange the records of the vector file,
otherwise the index file would be too big and the indexing inefficient.

\subsection{Summary command}

The summary command reports the list of statistics names, module names,
run ids, configuration names in the given files to the standard output.



\section{Other processing and plotting tools}

In case you have a large number of repeated experiments, you'll probably
want to automate processing of the output vector files. {\opp} lets you
use any tool you see fit for this purpose, because the output
vector files are text files and their format is simple enough to be
processed by common tools such as \textit{perl}, \textit{awk},
\textit{octave}, etc.

Output vector files (or files produced by \fprog{splitvec}) and
output scalar files can be analysed and/or plotted by
a number of applications in addition to the \fprog{Analysis Editor}.
These programs can produce output in various forms (on the screen,
as PostScript, in various image formats, etc.)

One straightforward solution is to import or paste them into spreadsheet
programs such as OpenOffice Calc, Microsoft Excel or GNOME Gnumeric.
These programs have good charting and statistical features, but the number
of rows is usually limited to about 32,000..64,000.
One useful functionality spreadsheets offer for analysing scalar files is
known as \textit{PivotTable} in Excel, and as \textit{DataPilot} in in OpenOffice.
The easiest way to import scalar files into them is via copy/paste
from Scalars.

Alternatively, one can use numerical packages such as \textit{Octave},
\textit{Matlab} or the statistics package \textit{R}.
In addition to their support for statistical computations, they can also
create various plots.

There are also open-source programs directly for plotting, \textit{Gnuplot}
still being the most commonly used one. Other, potentially more powerful ones
include \textit{MatPlotLib}, \textit{Grace}, \textit{ROOT} and \textit{PlotMTV}.


\subsection{GNU R}

R is a free software environment for statistical computing and graphics.
R has powerful plotting capabilities.

\subsection{MatPlotLib}

MatPlotlib is a plotting library for the Python programming language and
its NumPy numerical mathematics extension. It provides a "pylab" API designed
to closely resemble that of MATLAB, thereby making it easy to learn
for experienced MATLAB users. Matplotlib is written and maintained primarily
by John Hunter, and is distributed under a BSD-style license.

\subsection{Grace}

\textit{Grace} (also known as \textit{xmgrace}, a successor of \textit{ACE/gr} or
\textit{Xmgr}) is a GPL-ed powerful data visualization program
with a WYSIWIG point-and-click graphical user interface. It was developed for
Unix, but there is a Windows version, too.

You load the appropriate file by selecting it in a dialog box.
The icon bar and menu commands can be used to customize the graph.

As of June 2003, Grace 1.5.12 can export graphics to (E)PS, PDF, MIF, SVG,
PNM, JPEG and PNG formats. It has many useful features like built-in statistics
and analysis functions (e.g. correlation, histogram), fitting, splines, etc.,
and it also sports its own built-in programming language.


\subsection{ROOT}

\textit{ROOT} is a powerful object-oriented data analysis framework,
with strong support for plotting and graphics in general.
ROOT was developed at CERN, and is distributed under a BSD-like license.

ROOT is based on \textit{CINT}, a ``C/C++ interpreter''
aimed at processing C/C++ scripts. It is probably harder to get started
using ROOT than with either Gnuplot or Grace, but if you are serious
about analysing simulation results, you will find that ROOT provides
power and flexibility that would be unattainable the other two programs.

Curt Brune's page at Stanford (http://www.slac.stanford.edu/~curt/omnet++/)
shows examples what you can achieve using ROOT with {\opp}.


\subsection{Gnuplot}
\index{Gnuplot}

Gnuplot has an interactive command interface. To plot the data in
\texttt{mysim1.vec} and \texttt{mysim4.vec} (produced by \fprog{splitvec})
plotted in the same graph, you can type:

\begin{verbatim}
plot "mysim1.vec" with lines, "mysim4.vec" with lines
\end{verbatim}

To adjust the $y$ range, you would type:

\begin{verbatim}
set yrange [0:1.2]
replot
\end{verbatim}

Several commands are available to adjust ranges, plotting style, labels,
scaling etc. Gnuplot can also plot 3D graphs. Gnuplot
is available for Windows and other platforms.
On Windows, you can copy the resulting graph to the clipboard from
the Gnuplot window's system menu, then insert it into the application you
are working with.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "usman"
%%% End:

\chapter{Result Recording and Analysis}
\label{cha:analyzing-simulation-results}


\section{Result recording}

{\opp} provides built-in support for recording simulation results, via
\textit{output scalars} and \textit{output vectors}. Results may be
collected and recorded in two ways:

\begin{enumerate}
  \item Explicitly from simple modules and channels, using the C++ API
    provided by the simulation library
  \item By means of configuration, using declared statistics and the
    signal mechanism
\end{enumerate}

The first one is the traditional way of recording results. The second way
was introduced in {\opp} 4.1, and it is preferable because it allows you
to have much more control over the amount and form of results recorded,
without requiring constant changes to the simulation model.

\subsection{Using the C++ API}

With this approach, scalar and statistics results are collected in class
variables inside modules, then recorded in the finalization phase via
\ffunc{recordScalar()} calls. Simple statistics may be collected in
\ttt{double} and \ttt{long} variables. To record more details, like the
minimum/maximum value or the standard deviation, \cclass{cStdDev} and
\cclass{cWeightedStdDev} can be used, and for recording the distribution
there are several histogram classes and other distribution estimation
classes (\cclass{cDoubleHistogram}, \cclass{cLongHistogram},
\cclass{cPSquare}, \cclass{cKSplit}, and others). Vectors are recorded
using \cclass{cOutVector} objects. These classes are described in sections
\ref{sec:ch-sim-lib:statistics} and \ref{sec:ch-sim-lib:result-recording}.
Recording of individual vectors, scalars and statistics can be enabled or
disabled via the configuration (ini file), and it is also the place to set
up recording intervals for vectors.

The drawback of recording results directly from modules is that result
recording is hardcoded in modules, and even simple requirement changes
(e.g. record the average delay instead of each delay value, or vica versa)
requires code change or an excessive amount of result collection code
in the modules.

\subsection{Using declared statistics and signals}

This approach utilizes NED properties (section
\ref{sec:ch-ned-lang:properties}) and the signal mechanism (section
\ref{sec:simple-modules:signals}) in order to de-couple the generation of
results from their recording, thereby providing more flexibility in what to
record and in which form.

Statistics are declared in the NED files with the \ttt{@signal} property,
and modules emit values using the signal mechanism. The simulation
framework records data by adding result file writing listeners to modules.
By being able to choose what listeners to add, the user can control what to
record in the result files and what computations to apply before recording.
The section \label{sec:ch-simple-modules:statistic-signals} explains how to
instrument simple modules and channels for signals-based result recording.

The signals approach allows for calculation of aggregate statistics (such as the
total number of packet drops in the network) and for implementing a warm-up
period without support from module code. It also allows you to write
dedicated statistics collection modules for the simulation, also without
touching existing modules.

The same configuration options that were used to control result recording
with \cclass{cOutVector} and \ffunc{recordScalar()} also work when utilizing
the signals approach, and there are extra configuration options to make
the additional possibilities accessible.


\section{Configuring result collection}

\subsection{Result file names}

Simulation results are recorded into \textit{output scalar files} that
actually hold statistics results as well, and \textit{output vector
files}. The usual file extension for scalar files is \ttt{.sca}, and
for vector files \ttt{.vec}.

Every simulation run generates a single scalar file and a vector file.
The file names can be controlled with the \ttt{output-vector-file=}
and \ttt{output-scalar-file=} options. These options rarely need
to be used, because the default values are usually fine. The defaults
are:

\begin{inifile}
output-vector-file = "${resultdir}/${configname}-${runnumber}.vec"
output-scalar-file = "${resultdir}/${configname}-${runnumber}.sca"
\end{inifile}

Here, \ttt{\$\{resultdir\}} is the value of the \ttt{result-dir=}
configuration option which defaults to \ttt{results/}, and
\ttt{\$\{configname\}} and \ttt{\$\{runnumber\}} are the name of
the configuration name in the ini file (e.g. \ttt{[Config PureAloha]}),
and the run number. Thus, the above defaults generate file names
like \ttt{results/PureAloha-0.vec}, \ttt{results/PureAloha-1.vec},
and so on.

\begin{note}
  In {\opp} 3.x, the default result file names were \ttt{omnetpp.vec} and
  \ttt{omnetpp.sca}, and scalar files were always appended to, rather than
  being overwritten as in the 4.x version. When needed, the old behavior
  for scalar files can be turned back on by setting
  \ttt{output-scalar-file-append=true} in the configuration.
\end{note}

\subsection{Turning on/off scalar or vector recording globally}

The recording of scalar and/or vector results can be turned off with
the \ttt{scalar-recording=} and \ttt{vector-recording=} options (both
are turned on by default). These options actually provide per-vector
and per-scalar control, but disabling all scalars/vectors will turn off
file creation altogether. However, any existing file with the same name
will still be removed before the simulation starts.

\begin{inifile}
**.scalar-recording = false
**.vector-recording = false
\end{inifile}


\subsection{Warm-up period}

The \ttt{warmup-period=} option specifies the length of the initial
warm-up period. When set, results belonging to the first $x$ seconds
of the simulation will not be recorded into output vectors, and will
not be counted into the calculation of output scalars.
This option is useful for steady-state simulations. The default is 0s
(no warmup period).

Example:

\begin{inifile}
warmup-period = 20s
\end{inifile}

Note that modules that compute and record scalar results manually
(via \ffunc{recordScalar()}) will not automatically obey this setting.
These modules need to be modified so that they take the warm-up period
into account. The warm-up period is available via the
\ffunc{getWarmupPeriod()} method of the \ttt{simulation} object,
so the code that updates the corresponding state variables needs
to be surrounded with an \textit{if} statement.

Old:

\begin{cpp}
dropCount++;
\end{cpp}

New:

\begin{cpp}
if (simTime() >= simulation.getWarmupPeriod())
    dropCount++;
\end{cpp}


\subsection{Configuring scalar results}

Recording scalar results can be enabled or disabled individually, using
patterns. The syntax of the configuration option is
\textit{<module-full-path>.<scalar-name>.}\ttt{scalar-recording=}\textit{true/false},
where both \textit{<module-full-path>} and \textit{<scalar-name>}
may contain wildcards (see \ref{sec:ch-config-sim:wildcards}).
\textit{<scalar-name>} is the signal name, or the string passed to the
\ffunc{recordScalar()} call. By default, the recording of all scalars is
enabled.

The following example turns off recording all scalar results, except
end-to-end delays and those produced by TCP modules:

\begin{inifile}
**.tcp.**.scalar-recording = true
**.endToEndDelay.scalar-recording = true
**.scalar-recording = false
\end{inifile}

%% **.eed:histogram.scalar-recording=false    disables histogram

When recording signals as scalars, one has to define how to derive the
scalar value from the sequence of values emitted. One may be interested
in the final value, in the count of the values, in their mean, the minimum
or maximum value or other properties. This can be configured using the
\textit{<module-full-path>.<scalar-name>.}\ttt{scalar-recording-mode=}
configuration option. If \ttt{scalar-recording-mode=} is not defined
in the configuration or it is set to \ttt{auto}, the \ttt{modeHint} key
from the \ttt{@signal} property is used.

Several scalar recording modes can be specified, separated by comma.
Currently the following modes are supported:

\begin{description}
  \item[auto]: automatically select the best mode(s) for a signal. This mode
      currently selects \ttt{histogram} mode (because it records the most
      information), but this may change in future versions.
  \item[count]: record the number of values emitted; values are ignored
  \item[lastval]: record the last value
  \item[sum]: record the sum of the values
  \item[mean]: record the mean of the values
  \item[min]: record the minimum value
  \item[max]: record the maximum value
  \item[timeavg]: this one makes use of timestamps as well, and computes the
      time average, interpreting the signal as a step function (sample-hold)
  \item[stddev]: record the count, sum, mean, standard deviation, minimum
      and maximum of the values
  \item[histogram]: record everything \ttt{stddev} records, plus a histogram
      of the values (bins are set up automatically)
\end{description}

New ones cannot be defined at the moment; this feature is planned for future versions.

An example:

\begin{inifile}
**.queueLength.scalar-recording-mode = timeavg,max
\end{inifile}

In the result file, the recorded scalars will be suffixed with the name
of the operation, e.g. the mean of a \ttt{queueingTime} signal will
be recorded as \ttt{queueingTime:mean}.

%% TODO output-scalar-precision, output-vector-precision (already described somewhere else?)
%% ", CFG_INT, DEFAULT_PRECISION, "The number of significant digits for recording data into the output scalar file. The maximum value is ~15 (IEEE double precision).");


\subsection{Configuring output vectors}
\label{sec:ch-config-sim:outvectors}

The size of output vector files can easily reach the magnitude of several
hundred megabytes, but very often, only some of the recorded statistics are
interesting to the analyst. {\opp} allows you to control which vectors you
want to record, and to specify one or more result collection intervals. By
default, all output vectors are turned on for the whole duration the
simulation.

Output vectors can be configured with the \ttt{vector-recording=} and
\ttt{vector-recording-interval=} per-object options.

XXX the object name is...

As with parameter names, wildcards are allowed in the object
names and module path names.

\begin{inifile}
<module-pathname>.<objectname>.vector-recording = true/false
<module-pathname>.<objectname>.vector-recording-interval = start1..stop1,
                                                       start2..stop2, ...
\end{inifile}

Either \textit{start} or \textit{stop} can be omitted, to mean the
beginning and the end of the simulation, respectively.

The object name is the signal name as in the \ttt{@signal[name]},
or the string passed to \cclass{cOutVector}
in its constructor or with the \ffunc{setName()} member function.

Start and stop values can be any time specification accepted
in NED and config files (e.g. \textit{10h 30m 45.2s}).

An example:

\begin{inifile}
[General]
**.vector-recording-interval = 1s..60s
**.End-to-End Delay.vector-recording = true
**.Router2.**.vector-recording = true
**.vector-recording = false
\end{inifile}

The above configuration limits collection of all output vectors
to the 1s..60s interval, and disables collection of output vectors
except all end-to-end delays and the ones in any module called Router2.

XXX document this: vector-record-eventnumbers, default=true: Whether to record event numbers for an output vector. Simulation time and value are always recorded. Event numbers are needed by the Sequence Chart Tool, for example.

\begin{inifile}
**.vector-record-eventnumbers = true
\end{inifile}

XXX document these:
output-vectors-memory-limit: Total memory that can be used for buffering output vectors. Larger values produce less fragmented vector files (i.e. cause vector data to be grouped into larger chunks), and therefore allow more efficient processing later.
vector-max-buffered-values: For output vectors: the maximum number of values to buffer per vector, before writing out a block into the output vector file. The default is no per-vector limit (i.e. only the total memory limit is in effect


\subsection{Saving parameters as scalars}

When you are running several simulations with different parameter
settings, you'll usually want to refer to selected
input parameters in the result analysis as well -- for example when
drawing a throughput (or response time) versus load (or network
background traffic) plot. Average throughput or response time numbers
are saved into the output scalar files, and it is useful for the input
parameters to get saved into the same file as well.

For convenience, {\opp} automatically saves the iteration variables
into the output scalar file if they have numeric value, so they can
be referred to during result analysis.

\begin{warning}
    If an iteration variable has non-numeric value, it will not be recorded
    automatically and cannot be used during analysis. This can happen
    unintentionally if you specify units inside an iteration variable list:
\begin{inifile}
# NEVER USE:
**.host[*].generationInterval = exponential( ${mean=0.2s, 0.4s, 0.6s} )
# INSTEAD: Specify the unit outside of the variable
**.host[*].generationInterval = exponential( ${mean=0.2, 0.4, 0.6}s )
\end{inifile}
\end{warning}

Module parameters can also be saved, but this has to be
requested by the user, by configuring \ttt{save-as-scalar=true} for the
parameters in question. The configuration key is a pattern that
identifies the parameter, plus \ttt{.save-as-scalar}. An example:

\begin{inifile}
**.host[*].networkLoad.save-as-scalar = true
\end{inifile}

This looks simple enough. However, there are three pitfalls:
non-numeric parameters, too many matching parameters, and
random-valued volatile parameters.

First, the scalar file only holds numeric results, so non-numeric
parameters cannot be recorded -- that will result in a runtime
error.

Second, if wildcards in the pattern match too many parameters, that
might unnecessarily increase the size of the scalar file. For example,
if the \ttt{host[]} module vector size is 1000 in the example below, then the
same value (3) will be saved 1000 times into the scalar file, once for
each host.

\begin{inifile}
**.host[*].startTime = 3
**.host[*].startTime.save-as-scalar = true  # saves "3" once for each host
\end{inifile}

Third, recording a random-valued volatile parameter will just save a
random number from that distribution. This is rarely what you need, and
the simulation kernel will also issue a warning if this happens.

\begin{inifile}
**.interarrivalTime = exponential(1s)
**.interarrivalTime.save-as-scalar = true  # wrong: saves random values!
\end{inifile}

These pitfalls are quite common in practice, so it is usually better
to rely on the iteration variables in the result analysis.
That is, one can rewrite the above example as

\begin{inifile}
**.interarrivalTime = exponential( ${mean=1}s )
\end{inifile}

and refer to the \ttt{\$mean} iteration variable instead of the
interarrivalTime module parameter(s) during result analysis.
\ttt{save-as-scalar=true} is not needed, because iteration variables are
automatically saved into the result files.



\section{Result files}

Both output vector and scalar files are textual, line-oriented files.
The advantage of a text-based format is that it is very accessible
with a wide range of tools and languages. The format of result files is
documented in detail in Appendix \ref{cha:result-file-formats}.
  \footnote{Recording is actually configurable, and one can record
  results into a database as well, by writing appropriate result
  manager classes and activating them in the configuration.}

Vectors are recorded into a separate file for practical reasons: vector
data usually consume several magnitudes more disk space than others. Files
are self-describing: they contain many attributes of the simulation run:
the network, experiment-measurement-replication labels; iteration
variables; time/date, host, process id of the simulation, etc. By default,
each file contains data from one run only.
The vector file contains data clustered by vectors, and indexed for
efficient access. This allows for extracting certain vectors from the file,
and even near random access within vectors, without having to read the full
contents of the vector file even once.

XXX vector results, scalar results (scalars + stats/histograms)

, and \textit{statistics}. A scalar is a single number;
vectors are timestamped time series; and statistics are records composed of
statistical properties (mean, variance, minimum, maximum, etc.; possibly
also histogram data) of time series.

unique run id

attributes, e.g. experiment-measurement-replication

Although it has nothing to do with our main topic (ini files), this is a
good place to mention that the format of result files have been
extended to include meta info such as the run ID, network name, all
configuration settings, etc. These data make the files more
self-documenting, which can be valuable during the result analysis
phase, and increase reproducibility of the results. Another change is
that vector data are now recorded into the file clustered by the output
vectors, which (combined with index files) allows much more efficient
processing.



\subsection{Output vectors}
\label{sec:ch-ana-sim:output-vectors}

Output vectors are time series data: values with timestamps.
You can use output vectors to record end-to-end delays or
round trip times of packets, queue lengths, queueing times,
link utilization, the number of dropped packets, etc. --
anything that is useful to get a full picture of what happened
in the model during the simulation run.

Output vectors are recorded from simple modules, by \cclass{cOutVector} objects
(see section \ref{sec:ch-sim-lib:coutvector}). Since output vectors usually
record a large amount of data, in \ffilename{omnetpp.ini} you can disable vectors
or specify a simulation time interval for recording
(see section \ref{sec:ch-config-sim:outvectors}).

All \cclass{cOutVector} objects write to the same, common file.
The following sections describe the format of the file, and
how to process it.


\subsection{Format of output vector files}

An output vector file\index{output!vector file} contains several
series of data produced during simulation. The file is textual, and it
looks like this:

\begin{filelisting}
# net-1.vec
vector 1   "subnet[4].term[12]"  "response time"  TV
1  12.895  2355.66666666
1  14.126  4577.66664666
vector 2   "subnet[4].srvr"  "queue length"  TV
2  16.960  2.00000000000.63663666
1  23.086  2355.66666666
2  24.026  8.00000000000.44766536
\end{filelisting}

There two types of lines: vector declaration lines (beginning with
the word \ttt{vector}), and data lines.
A \textit{vector declaration line} introduces a new output vector, and
its columns are: vector Id, module of creation, name of \cclass{cOutVector}
object, and multiplicity (usually 1). Actual data recorded in this
vector are on \textit{data lines} which begin with the vector Id.
Further columns on data lines are the simulation time and the recorded value.

vector data clustering for efficiency

indexed access

how to configure the IndexVectorFileManager (?)


\subsection{Scalar results}
\label{sec:ch-ana-sim:output-scalars}

Scalar results are recorded with \ffunc{recordScalar()} calls,
usually from the \ttt{finish()} methods of modules.


\subsubsection{Format of scalar files}

The corresponding output scalar file (by default, \ffilename{omnetpp.sca})
will look like this:

\begin{filelisting}
scalar "lan.hostA.mac" "frames sent"                99
scalar "lan.hostA.mac" "frames rcvd"                3088
scalar "lan.hostA.mac" "bytes sent"                 64869
scalar "lan.hostA.mac" "bytes rcvd"                 3529448
...
\end{filelisting}

Every \ffunc{record()} call generates one "scalar" line in the file.
(If you record statistics objects (\cclass{cStatictic} subclasses
such as \cclass{cStdDev}) via their \ffunc{record()} methods,
they'll generate several lines: mean, standard deviation, etc.)
In addition, several simulation runs can record their results into a single file --
this facilitates comparing them, creating x-y plots
(\textit{offered load vs throughput}-type diagrams), etc.



\section{The Analysis Tool in the Simulation IDE}

The Simulation IDE provides an Analysis Tool for analysis and visualization
of simulation results. The Analysis Tool lets you load several result files
at once, and presents their contents somewhat like a database. You can
browse the results, select the particular data you are interested in
(scalars, vectors, histograms), apply processing steps, and create various
charts or plots from them. Data selection, processing and charting steps
can be freely combined, resulting in a high degree of freedom.
These steps are grouped into and stored as "recipes", which get automatically
re-applied when new result files are added or existing files are
replaced. This automation spares the user lots of repetitive manual work,
without resorting to scripting.

The Analysis Tool is covered in detail in the User Guide.


\section{Scave Tool}
\index{scavetool}\label{sec:ana-sim:scavetool}

Much of the IDE Analysis Tool's functionality is available on the command
line as well, via the \fprog{scavetool} program. \fprog{scavetool} is
suitable for filtering and basic processing of result files, and
exporting the result in various formats digestible for other tools.
\fprog{scavetool} has no graphics capabilities, but it can be used
to produce files that can be directly plotted with other tools like
gnuplot (see \ref{sec:ana-sim:gnuplot}).

When \fprog{scavetool} is invoked without arguments, it prints usage information:

\begin{commandline}
scavetool <command> [options] <file>...
\end{commandline}

\subsection{The filter command}

The \textit{filter} command allows you to filter and/or convert result files.

A filter can be specified with the \textit{-p <filter>} option.
The filter is one or more \textit{<pattern>} or \textit{<fieldname>(<pattern>)}
expressions connected with \ttt{AND}, \ttt{OR} and \ttt{NOT} operators;
a naked \textit{<pattern>} is understood as \ttt{name(}\textit{<pattern>}\ttt{)}.
For example, the filter \ttt{"module(**.sink) AND name(delay)"} (or just
\ttt{"module(**.sink) AND delay"}) selects the \ttt{delay} vectors from all
\ttt{sink} modules.

The possible field names are:

\begin{itemize}
    \item\tbf{file}: full path of the result file
    \item\tbf{run}: run identifier
    \item\tbf{module}: module name
    \item\tbf{name}: vector name
    \item\tbf{attr:<runAttribute>}: value of an attribute of the run,
        e.g. \ttt{experiment}, \ttt{datetime} or \ttt{network}
    \item\tbf{param:<moduleParameter>}: value of the parameter in the run
\end{itemize}

Processing operations can be applied to vectors by the
\textit{-a <function>(<parameterlist>)} option. You can list
the available functions and their parameters with the \textit{info} command.

The name and format of the output file can be specified with the
\textit{-O <file>} and \textit{-F <formatname>} options, where
the format name is one of the following:

\begin{itemize}
    \item\tbf{vec}: vector file (default)
    \item\tbf{csv}: CSV file
    \item\tbf{octave}: Octave text file
    \item\tbf{matlab}: Matlab script file
\end{itemize}

The following example writes the window-averaged queuing times stored
in \ttt{in.vec} into \ttt{out.vec}:

\begin{commandline}
scavetool filter -p "queuing time" -a winavg(10) -O out.vec in.vec
\end{commandline}

The next example writes the queueing and transmission times of \ttt{sink}
modules into CSV files. It generates a separate file for each vector,
named \ttt{out-1.csv}, \ttt{out-2.csv}, etc.

\begin{commandline}
scavetool filter -p "module(**.sink) AND
                    (\"queueing time\" OR \"transmission time\")"
                 -O out.csv -F csv in.vec
\end{commandline}

The generated CSV files contain a header and two columns:

\begin{filelisting}
time,"Queue.sink.queueing time"
2.231807576851,0
7.843802235089,0
15.797137536721,3.59449
21.730758362277,6.30398
[...]
\end{filelisting}


\subsection{The index command}

If the index file was deleted or the vector file was modified, you need to
rebuild the index file before running the filter command:

\begin{commandline}
scavetool index Aloha-1.vec
\end{commandline}

Normally the vector data is written in blocks into the vector file.
However, if the vector file was generated by an older version of the
\cclass{cOutputVectorManager}, it might not be so. In this case you have
to specify the -r option to rearrange the records of the vector file,
otherwise the index file would be too big and the indexing inefficient.

\subsection{The summary command}

The \textit{summary} command reports the list of statistics names, module names,
run ids, configuration names in the given files to the standard output.

\begin{commandline}
scavetool summary Aloha-1.vec
\end{commandline}


\section{Alternative statistical analysis and plotting tools}

There are several programs and packages that can also be used to analyse
result files, and create various plots and charts from them.


\subsection{Spreadsheet programs}
\index{Spreadsheets}

One straightforward solution is to use spreadsheets such as OpenOffice
Calc, Microsoft Excel, Gnumeric or KSpread. Data can be imported from csv
or other formats, exported with \fprog{scavetool} (see
\ref{sec:ana-sim:scavetool}).

Spreadsheets have good charting and statistical features. A useful
functionality spreadsheets offer for analysing scalar files is
\textit{PivotTable} (Excel) or \textit{DataPilot} (OpenOffice). The
drawback of using spreadsheets is limited automation, leading to tedious
and repetitive tasks; also, the number of rows is usually limited to about
32,000..64,000, that can be painful when working with large vector files.


\subsection{GNU R}
\label{sec:ana-sim:gnu-r}\index{GNU R}

R is a free software environment for statistical computing and graphics.
R has an excellent programming language and powerful plotting capabilities,
and it is supported on all major operating systems and platforms.

R is widely used for statistical software development and data analysis.
The program uses a command line interface, though several graphical user
interfaces are available.

Several {\opp}-related packages such as SimProcTC and Syntony already
use R for data analysis and plotting. In the future, {\opp} is going
to be extended with features that further facilitate using it with R.


\subsection{MATLAB or Octave}
\index{Matlab}\index{Octave}

MATLAB is a commercial numerical computing environment and programming language.
MATLAB allows easy matrix manipulation, plotting of functions and data,
implementation of algorithms, creation of user interfaces, and interfacing
with programs in other languages.

Octave is an open-source Matlab-like package, available on nearly all platforms.
Currently Octave relies on Gnuplot for plotting, and has more limited
graphics capabilities than GNU R or MATLAB.

\subsection{NumPy and MatPlotLib}
\index{NumPy}\index{MatPlotLib}

MatPlotlib is a plotting library for the Python programming language and
its NumPy numerical mathematics extension. It provides a "pylab" API designed
to closely resemble that of MATLAB, thereby making it easy to learn
for experienced MATLAB users. Matplotlib is distributed under a BSD-style
license.


\subsection{ROOT}
\index{ROOT}

\textit{ROOT} is a powerful object-oriented data analysis framework,
with strong support for plotting and graphics in general.
ROOT was developed at CERN, and is distributed under a BSD-like license.

ROOT is based on \textit{CINT}, a ``C/C++ interpreter''
aimed at processing C/C++ scripts. It is probably harder to get started
using ROOT than with either Gnuplot or Grace, but if you are serious
about analysing simulation results, you will find that ROOT provides
power and flexibility that would be unattainable the other two programs.

Curt Brune's page at Stanford (http://www.slac.stanford.edu/~curt/omnet++/)
shows examples what you can achieve using ROOT with {\opp}.


\subsection{Gnuplot}
\label{sec:ana-sim:gnuplot}\index{Gnuplot}

Gnuplot is a very popular command-line program that can generate two-
and three-dimensional plots of functions and data. The program runs
on all major platforms, and it is well supported.

Gnuplot has an interactive command interface. For example, if you have
the data files \texttt{foo.csv} and \texttt{bar.csv} that contain
two values per line ($x$ $y$; such files can be exported with
\fprog{scavetool} from vector files), you can plot them in the same
graph by typing:

\begin{commandline}
plot "foo.csv" with lines, "bar.csv" with lines
\end{commandline}

To adjust the $y$ range, you would type:

\begin{commandline}
set yrange [0:1.2]
replot
\end{commandline}

Several commands are available to adjust ranges, plotting style, labels,
scaling etc. On Windows, you can copy the resulting graph to the clipboard from
the Gnuplot window's system menu, then insert it into the application you
are working with.


\subsection{Grace}
\index{Grace}

\textit{Grace} (also known as \textit{xmgrace}, a successor of
\textit{ACE/gr} or \textit{Xmgr}) is a powerful GPL data visualization
program with a menu-and-dialog graphical user interface for X and Motif. It
has also been ported to Windows.

Grace can export graphics in various raster and vector formats, and has
many useful features like built-in statistics and analysis functions (e.g.
correlation, histogram), fitting, splines, etc., and it also has a built-in
programming language.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "usman"
%%% End:


